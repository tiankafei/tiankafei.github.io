<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Hive学习笔记 | tiankafei - java相关技术栈</title>
    <meta name="generator" content="VuePress 1.9.7">
    
    <meta name="description" content="自己写的一些东西的记录，包括代码与笔记，jdk最低支持1.8">
    
    <link rel="preload" href="/assets/css/0.styles.d6ad21ed.css" as="style"><link rel="preload" href="/assets/js/app.a9dae821.js" as="script"><link rel="preload" href="/assets/js/2.63c13255.js" as="script"><link rel="preload" href="/assets/js/100.ffa5fdd6.js" as="script"><link rel="prefetch" href="/assets/js/10.63a451e7.js"><link rel="prefetch" href="/assets/js/101.f8810a98.js"><link rel="prefetch" href="/assets/js/102.dc5c5b06.js"><link rel="prefetch" href="/assets/js/103.2bbb57b2.js"><link rel="prefetch" href="/assets/js/104.0e06cbf9.js"><link rel="prefetch" href="/assets/js/105.80388754.js"><link rel="prefetch" href="/assets/js/106.efe79d8e.js"><link rel="prefetch" href="/assets/js/107.c315bce6.js"><link rel="prefetch" href="/assets/js/108.b9cdff35.js"><link rel="prefetch" href="/assets/js/109.ef62cb54.js"><link rel="prefetch" href="/assets/js/11.723eb809.js"><link rel="prefetch" href="/assets/js/110.2178b947.js"><link rel="prefetch" href="/assets/js/111.0ad18f88.js"><link rel="prefetch" href="/assets/js/112.55c9a439.js"><link rel="prefetch" href="/assets/js/113.31ed11d3.js"><link rel="prefetch" href="/assets/js/12.54a5ae97.js"><link rel="prefetch" href="/assets/js/13.1e60f441.js"><link rel="prefetch" href="/assets/js/14.7f60d340.js"><link rel="prefetch" href="/assets/js/15.e2ad08cf.js"><link rel="prefetch" href="/assets/js/16.cb787676.js"><link rel="prefetch" href="/assets/js/17.6a7e1cc0.js"><link rel="prefetch" href="/assets/js/18.bcd99a51.js"><link rel="prefetch" href="/assets/js/19.d868c980.js"><link rel="prefetch" href="/assets/js/20.cd1d3aec.js"><link rel="prefetch" href="/assets/js/21.1cbdeb82.js"><link rel="prefetch" href="/assets/js/22.200922b5.js"><link rel="prefetch" href="/assets/js/23.7aaf2e55.js"><link rel="prefetch" href="/assets/js/24.68b66e3a.js"><link rel="prefetch" href="/assets/js/25.d3706361.js"><link rel="prefetch" href="/assets/js/26.60467ea8.js"><link rel="prefetch" href="/assets/js/27.c9d89620.js"><link rel="prefetch" href="/assets/js/28.04e72281.js"><link rel="prefetch" href="/assets/js/29.88491397.js"><link rel="prefetch" href="/assets/js/3.4c9060ec.js"><link rel="prefetch" href="/assets/js/30.049ea996.js"><link rel="prefetch" href="/assets/js/31.d8fa6176.js"><link rel="prefetch" href="/assets/js/32.64be24c1.js"><link rel="prefetch" href="/assets/js/33.50a4f525.js"><link rel="prefetch" href="/assets/js/34.984e4c0d.js"><link rel="prefetch" href="/assets/js/35.b5807b4d.js"><link rel="prefetch" href="/assets/js/36.b3552f1e.js"><link rel="prefetch" href="/assets/js/37.3d64ff94.js"><link rel="prefetch" href="/assets/js/38.ee6eb07d.js"><link rel="prefetch" href="/assets/js/39.ecb8e9fa.js"><link rel="prefetch" href="/assets/js/4.94733d25.js"><link rel="prefetch" href="/assets/js/40.53032794.js"><link rel="prefetch" href="/assets/js/41.74dc1c8b.js"><link rel="prefetch" href="/assets/js/42.c3123f54.js"><link rel="prefetch" href="/assets/js/43.eda3fce2.js"><link rel="prefetch" href="/assets/js/44.29d9a9c9.js"><link rel="prefetch" href="/assets/js/45.cc68a0a2.js"><link rel="prefetch" href="/assets/js/46.aa00e89a.js"><link rel="prefetch" href="/assets/js/47.3378a4d7.js"><link rel="prefetch" href="/assets/js/48.b964e43f.js"><link rel="prefetch" href="/assets/js/49.b1256dc5.js"><link rel="prefetch" href="/assets/js/5.2ea06e07.js"><link rel="prefetch" href="/assets/js/50.ee5ba818.js"><link rel="prefetch" href="/assets/js/51.1454b738.js"><link rel="prefetch" href="/assets/js/52.f804a4d4.js"><link rel="prefetch" href="/assets/js/53.a54e2f3a.js"><link rel="prefetch" href="/assets/js/54.978bb8ed.js"><link rel="prefetch" href="/assets/js/55.324e1abb.js"><link rel="prefetch" href="/assets/js/56.67def1c2.js"><link rel="prefetch" href="/assets/js/57.8efdacf3.js"><link rel="prefetch" href="/assets/js/58.a8a5419d.js"><link rel="prefetch" href="/assets/js/59.e6e825b3.js"><link rel="prefetch" href="/assets/js/6.8d81f0ec.js"><link rel="prefetch" href="/assets/js/60.1a8fb4b8.js"><link rel="prefetch" href="/assets/js/61.7803f21b.js"><link rel="prefetch" href="/assets/js/62.a79a20ee.js"><link rel="prefetch" href="/assets/js/63.c9821bae.js"><link rel="prefetch" href="/assets/js/64.54435ae4.js"><link rel="prefetch" href="/assets/js/65.4569f93a.js"><link rel="prefetch" href="/assets/js/66.4a50b72f.js"><link rel="prefetch" href="/assets/js/67.7c1b3a9b.js"><link rel="prefetch" href="/assets/js/68.218dfc69.js"><link rel="prefetch" href="/assets/js/69.b685730f.js"><link rel="prefetch" href="/assets/js/7.a054ba90.js"><link rel="prefetch" href="/assets/js/70.b64a7073.js"><link rel="prefetch" href="/assets/js/71.f59c809d.js"><link rel="prefetch" href="/assets/js/72.9f19043b.js"><link rel="prefetch" href="/assets/js/73.9afc612e.js"><link rel="prefetch" href="/assets/js/74.9db3e6cb.js"><link rel="prefetch" href="/assets/js/75.eb8c0c13.js"><link rel="prefetch" href="/assets/js/76.d2029c62.js"><link rel="prefetch" href="/assets/js/77.64d7f71a.js"><link rel="prefetch" href="/assets/js/78.87612624.js"><link rel="prefetch" href="/assets/js/79.665071de.js"><link rel="prefetch" href="/assets/js/8.95d6723a.js"><link rel="prefetch" href="/assets/js/80.0d287af5.js"><link rel="prefetch" href="/assets/js/81.b1ca2efe.js"><link rel="prefetch" href="/assets/js/82.70887aa9.js"><link rel="prefetch" href="/assets/js/83.01b5392f.js"><link rel="prefetch" href="/assets/js/84.45f0d71f.js"><link rel="prefetch" href="/assets/js/85.83aaf33d.js"><link rel="prefetch" href="/assets/js/86.fea15cee.js"><link rel="prefetch" href="/assets/js/87.d95cc309.js"><link rel="prefetch" href="/assets/js/88.23544aef.js"><link rel="prefetch" href="/assets/js/89.e048a592.js"><link rel="prefetch" href="/assets/js/9.d08f0e4c.js"><link rel="prefetch" href="/assets/js/90.f0b260f4.js"><link rel="prefetch" href="/assets/js/91.7d2be649.js"><link rel="prefetch" href="/assets/js/92.d09eb325.js"><link rel="prefetch" href="/assets/js/93.d29388bb.js"><link rel="prefetch" href="/assets/js/94.40904e43.js"><link rel="prefetch" href="/assets/js/95.c2dcf5bb.js"><link rel="prefetch" href="/assets/js/96.8661e51c.js"><link rel="prefetch" href="/assets/js/97.a1f2ef5f.js"><link rel="prefetch" href="/assets/js/98.07dab9bf.js"><link rel="prefetch" href="/assets/js/99.bbb5044b.js">
    <link rel="stylesheet" href="/assets/css/0.styles.d6ad21ed.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">tiankafei - java相关技术栈</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/tiankafei-docs-java/Java基础.html" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/tiankafei-docs-spring/spring学习笔记/" class="nav-link">
  Spring
</a></div><div class="nav-item"><a href="/tiankafei-docs-架构/MySQL调优/" class="nav-link">
  架构
</a></div><div class="nav-item"><a href="/tiankafei-docs-大数据/centos7安装配置Hadoop/" class="nav-link">
  大数据
</a></div><div class="nav-item"><a href="/tiankafei-docs-linux/centos常用命令/" class="nav-link">
  Linux
</a></div><div class="nav-item"><a href="/tiankafei-docs-云/Centos7安装Docker并配置使用/" class="nav-link">
  云
</a></div><div class="nav-item"><a href="/tiankafei-docs-other/git命令/" class="nav-link">
  其他
</a></div><div class="nav-item"><a href="/tiankafei-docs-en/词性语法学习/" class="nav-link">
  英语
</a></div><div class="nav-item"><a href="https://github.com/tiankafei/tiankafei" target="_blank" rel="noopener noreferrer" class="nav-link external">
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/tiankafei-docs-java/Java基础.html" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/tiankafei-docs-spring/spring学习笔记/" class="nav-link">
  Spring
</a></div><div class="nav-item"><a href="/tiankafei-docs-架构/MySQL调优/" class="nav-link">
  架构
</a></div><div class="nav-item"><a href="/tiankafei-docs-大数据/centos7安装配置Hadoop/" class="nav-link">
  大数据
</a></div><div class="nav-item"><a href="/tiankafei-docs-linux/centos常用命令/" class="nav-link">
  Linux
</a></div><div class="nav-item"><a href="/tiankafei-docs-云/Centos7安装Docker并配置使用/" class="nav-link">
  云
</a></div><div class="nav-item"><a href="/tiankafei-docs-other/git命令/" class="nav-link">
  其他
</a></div><div class="nav-item"><a href="/tiankafei-docs-en/词性语法学习/" class="nav-link">
  英语
</a></div><div class="nav-item"><a href="https://github.com/tiankafei/tiankafei" target="_blank" rel="noopener noreferrer" class="nav-link external">
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>大数据</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/tiankafei-docs-大数据/centos7安装配置Hadoop.html" class="sidebar-link">CentOS7安装Hadoop</a></li><li><a href="/tiankafei-docs-大数据/hadoop学习笔记.html" class="sidebar-link">大数据启蒙</a></li><li><a href="/tiankafei-docs-大数据/Hadoop程序运行的三种方式.html" class="sidebar-link">Hadoop程序运行的三种方式</a></li><li><a href="/tiankafei-docs-大数据/hive学习笔记.html" class="active sidebar-link">Hive学习笔记</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive产生的原因" class="sidebar-link">Hive产生的原因</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive是什么" class="sidebar-link">hive是什么</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#数据仓库" class="sidebar-link">数据仓库</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#oltp" class="sidebar-link">OLTP</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#olap" class="sidebar-link">OLAP</a></li></ul></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#数据库与数据仓库的区别" class="sidebar-link">数据库与数据仓库的区别</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive的架构图" class="sidebar-link">Hive的架构图</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive的服务-角色" class="sidebar-link">Hive的服务（角色）</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#用户访问接口" class="sidebar-link">用户访问接口</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#thrift-server" class="sidebar-link">Thrift Server:</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#driver" class="sidebar-link">Driver</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#metastore" class="sidebar-link">metastore</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive的访问流程图" class="sidebar-link">Hive的访问流程图</a></li></ul></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive的基本sql操作" class="sidebar-link">Hive的基本SQL操作</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive-ddl-数据库定义语言" class="sidebar-link">Hive DDL（数据库定义语言）</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive-dml" class="sidebar-link">Hive DML</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive-serde" class="sidebar-link">Hive Serde</a></li></ul></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hiveserver2" class="sidebar-link">HiveServer2</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#pom依赖" class="sidebar-link">pom依赖</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#jdbc访问" class="sidebar-link">jdbc访问</a></li></ul></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive函数" class="sidebar-link">Hive函数</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#内置运算符" class="sidebar-link">内置运算符</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#内置函数" class="sidebar-link">内置函数</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#内置的聚合函数-udaf" class="sidebar-link">内置的聚合函数（UDAF）</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#内置表生成函数-udtf" class="sidebar-link">内置表生成函数（UDTF）</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#自定义函数" class="sidebar-link">自定义函数</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive使用sql计算word-count" class="sidebar-link">hive使用sql计算word count</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive-sql解析工具" class="sidebar-link">hive - sql解析工具</a></li></ul></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive参数操作" class="sidebar-link">Hive参数操作</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive参数介绍" class="sidebar-link">hive参数介绍</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive参数的设置方式" class="sidebar-link">hive参数的设置方式</a></li></ul></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive运行方式" class="sidebar-link">Hive运行方式</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#命令行方式或者控制台模式" class="sidebar-link">命令行方式或者控制台模式</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#脚本运行方式-实际生产环境中用最多" class="sidebar-link">脚本运行方式（实际生产环境中用最多）</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#jdbc方式-hiveserver2" class="sidebar-link">JDBC方式：hiveserver2</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#web-gui接口-hwi、hue等" class="sidebar-link">web GUI接口（hwi、hue等）</a></li></ul></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive视图" class="sidebar-link">Hive视图</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive-lateral-view" class="sidebar-link">Hive Lateral View</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive普通视图" class="sidebar-link">Hive普通视图</a></li></ul></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive索引" class="sidebar-link">Hive索引</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive权限管理" class="sidebar-link">Hive权限管理</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive授权模型介绍" class="sidebar-link">hive授权模型介绍</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#基于sql标准的hive授权" class="sidebar-link">基于SQL标准的Hive授权</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive权限配置" class="sidebar-link">Hive权限配置</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive权限管理命令" class="sidebar-link">Hive权限管理命令</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive权限分配图" class="sidebar-link">Hive权限分配图</a></li></ul></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive优化" class="sidebar-link">Hive优化</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#查看hive执行计划-小白慎用" class="sidebar-link">查看Hive执行计划（小白慎用）</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive的抓取策略" class="sidebar-link">Hive的抓取策略</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive本地模式" class="sidebar-link">Hive本地模式</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive并行模式" class="sidebar-link">Hive并行模式</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive严格模式" class="sidebar-link">Hive严格模式</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive排序" class="sidebar-link">Hive排序</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive-join" class="sidebar-link">Hive join</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#map-side聚合" class="sidebar-link">Map-Side聚合</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#合并小文件" class="sidebar-link">合并小文件</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#合理设置map以及reduce的数量" class="sidebar-link">合理设置Map以及Reduce的数量</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#jvm重用" class="sidebar-link">JVM重用</a></li></ul></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hadoop压缩配置" class="sidebar-link">Hadoop压缩配置</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#mr支持的压缩编码" class="sidebar-link">MR支持的压缩编码</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#压缩配置参数" class="sidebar-link">压缩配置参数</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#开启map输出阶段压缩" class="sidebar-link">开启Map输出阶段压缩</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#开启reduce输出阶段压缩" class="sidebar-link">开启Reduce输出阶段压缩</a></li></ul></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#文件存储格式" class="sidebar-link">文件存储格式</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#列式存储和行式存储" class="sidebar-link">列式存储和行式存储</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#textfile格式" class="sidebar-link">TEXTFILE格式</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#orc格式" class="sidebar-link">ORC格式</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#parquet格式" class="sidebar-link">PARQUET格式</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#主流文件存储格式对比实验" class="sidebar-link">主流文件存储格式对比实验</a></li></ul></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#存储和压缩结合" class="sidebar-link">存储和压缩结合</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#hive-high-avaliable" class="sidebar-link">hive—high Avaliable</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#执行配置" class="sidebar-link">执行配置</a></li><li class="sidebar-sub-header"><a href="/tiankafei-docs-大数据/hive学习笔记.html#使用jdbc或者beeline两种方式进行访问" class="sidebar-link">使用jdbc或者beeline两种方式进行访问</a></li></ul></li></ul></li><li><a href="/tiankafei-docs-大数据/centos7安装配置HBase.html" class="sidebar-link">centos7安装配置HBase</a></li><li><a href="/tiankafei-docs-大数据/hbase学习笔记.html" class="sidebar-link">HBase学习笔记</a></li><li><a href="/tiankafei-docs-大数据/大数据项目-日志收集分析.html" class="sidebar-link">大数据项目-日志收集分析</a></li><li><a href="/tiankafei-docs-大数据/flume学习笔记.html" class="sidebar-link">Flume</a></li><li><a href="/tiankafei-docs-大数据/sqoop学习笔记.html" class="sidebar-link">sqoop的简单概论</a></li><li><a href="/tiankafei-docs-大数据/centos7安装配置Spark.html" class="sidebar-link">Centos7安装Scala</a></li><li><a href="/tiankafei-docs-大数据/scala学习笔记.html" class="sidebar-link">Scala学习</a></li><li><a href="/tiankafei-docs-大数据/centos7安装配置Flink.html" class="sidebar-link">Centos7安装Flink</a></li><li><a href="/tiankafei-docs-大数据/Kafka学习笔记.html" class="sidebar-link">Kafka</a></li><li><a href="/tiankafei-docs-大数据/数仓体系.html" class="sidebar-link">数仓体系</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="hive学习笔记"><a href="#hive学习笔记" class="header-anchor">#</a> Hive学习笔记</h1> <h2 id="hive产生的原因"><a href="#hive产生的原因" class="header-anchor">#</a> Hive产生的原因</h2> <ol><li>方便对文件及数据的元数据进行管理，提供统一的元数据管理方式</li> <li>提供更加简单的方式来访问大规模的数据集，使用SQL语言进行数据分析</li></ol> <h2 id="hive是什么"><a href="#hive是什么" class="header-anchor">#</a> hive是什么</h2> <p><font color="red"><strong>企业级数据仓库</strong></font></p> <p>Hive使用SQL语句来进行数据分析，由SQL语句到具体的任务执行还需要经过解释器，编译器，优化器，执行器四部分才能完成。</p> <ol><li>解释器：调用语法解释器和语义分析器将SQL语句转换成对应的可执行的java代码或者业务代码</li> <li>编译器：将对应的java代码转换成字节码文件或者jar包</li> <li>优化器：从SQL语句到java代码的解析转化过程中需要调用优化器，进行相关策略的优化，实现最优的查询性能</li> <li>执行器：当业务代码转换完成之后，需要上传到MapReduce的集群中执行</li></ol> <h2 id="数据仓库"><a href="#数据仓库" class="header-anchor">#</a> 数据仓库</h2> <p>​		数据处理大致可以分成两大类：联机事务处理OLTP（on-line transaction processing）、联机分析处理OLAP（On-Line Analytical Processing）。OLTP是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。OLAP是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。</p> <h3 id="oltp"><a href="#oltp" class="header-anchor">#</a> OLTP</h3> <p>​		OLTP，也叫联机事务处理（Online Transaction Processing），表示事务性非常高的系统，一般都是高可用的在线系统，以小的事务以及小的查询为主，评估其系统的时候，一般看其每秒执行的Transaction以及Execute SQL的数量。在这样的系统中，单个数据库每秒处理的Transaction往往超过几百个，或者是几千个，Select 语句的执行量每秒几千甚至几万个。典型的OLTP系统有电子商务系统、银行、证券等，如美国eBay的业务数据库，就是很典型的OLTP数据库。</p> <h3 id="olap"><a href="#olap" class="header-anchor">#</a> OLAP</h3> <p>​		OLAP（On-Line Analysis Processing）在线分析处理是一种共享多维信息的快速分析技术；OLAP利用多维数据库技术使用户从不同角度观察数据；OLAP用于支持复杂的分析操作，侧重于对管理人员的决策支持，可以满足分析人员快速、灵活地进行大数据复量的复杂查询的要求，并且以一种直观、易懂的形式呈现查询结果，辅助决策。</p> <h2 id="数据库与数据仓库的区别"><a href="#数据库与数据仓库的区别" class="header-anchor">#</a> 数据库与数据仓库的区别</h2> <ol><li>数据库是对业务系统的支撑，性能要求高，相应的时间短，而数据仓库则对响应时间没有太多的要求，当然也是越快越好</li> <li>数据库存储的是某一个产品线或者某个业务线的数据，数据仓库可以将多个数据源的数据经过统一的规则清洗之后进行集中统一管理</li> <li>数据库中存储的数据可以修改，无法保存各个历史时刻的数据，数据仓库可以保存各个时间点的数据，形成时间拉链表，可以对各个历史时刻的数据做分析</li> <li>数据库一次操作的数据量小，数据仓库操作的数据量大</li> <li>数据库使用的是实体-关系（E-R）模型，数据仓库使用的是星型模型或者雪花模型</li> <li>数据库是面向事务级别的操作，数据仓库是面向分析的操作</li></ol> <h2 id="hive的架构图"><a href="#hive的架构图" class="header-anchor">#</a> Hive的架构图</h2> <p><img src="/images/hive%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="hive架构图"></p> <h2 id="hive的服务-角色"><a href="#hive的服务-角色" class="header-anchor">#</a> Hive的服务（角色）</h2> <h3 id="用户访问接口"><a href="#用户访问接口" class="header-anchor">#</a> 用户访问接口</h3> <ol><li>CLI（Command Line Interface）：用户可以使用Hive自带的命令行接口执行Hive QL、设置参数等功能。</li> <li>JDBC/ODBC：用户可以使用JDBC或者ODBC的方式在代码中操作Hive。</li> <li>Web GUI：浏览器接口，用户可以在浏览器中对Hive进行操作（2.2之后淘汰）。</li></ol> <h3 id="thrift-server"><a href="#thrift-server" class="header-anchor">#</a> Thrift Server:</h3> <blockquote><p>Thrift服务运行客户端使用Java、C++、Ruby等多种语言，通过编程的方式远程访问Hive。</p></blockquote> <h3 id="driver"><a href="#driver" class="header-anchor">#</a> Driver</h3> <blockquote><p>Hive Driver是Hive的核心，其中包含解释器、编译器、优化器等各个组件，完成从SQL语句到MapReduce任务的解析优化执行过程。</p></blockquote> <h3 id="metastore"><a href="#metastore" class="header-anchor">#</a> metastore</h3> <blockquote><p>Hive的元数据存储服务，一般将数据存储在关系型数据库中，为了实现Hive元数据的持久化操作，Hive的安装包中自带了Derby内存数据库，但是在实际的生产环境中一般使用mysql来存储元数据。</p></blockquote> <h3 id="hive的访问流程图"><a href="#hive的访问流程图" class="header-anchor">#</a> Hive的访问流程图</h3> <p><img src="/images/%E8%AE%BF%E9%97%AE%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="访问流程图"></p> <h2 id="hive的基本sql操作"><a href="#hive的基本sql操作" class="header-anchor">#</a> Hive的基本SQL操作</h2> <h3 id="hive-ddl-数据库定义语言"><a href="#hive-ddl-数据库定义语言" class="header-anchor">#</a> Hive DDL（数据库定义语言）</h3> <h4 id="数据库的基本操作"><a href="#数据库的基本操作" class="header-anchor">#</a> 数据库的基本操作</h4> <blockquote><p>注意：当进入hive的命令行开始编写SQL语句的时候，如果没有任何相关的数据库操作，那么默认情况下，所有的表存在于default数据库，在hdfs上的展示形式是将此数据库的表保存在hive的默认路径下，如果创建了数据库，那么会在hive的默认路径下生成一个database_name.db的文件夹，此数据库的所有表会保存在database_name.db的目录下。</p></blockquote> <h5 id="展示所有数据库"><a href="#展示所有数据库" class="header-anchor">#</a> 展示所有数据库</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">--展示所有数据库</span>
<span class="token keyword">show</span> <span class="token keyword">databases</span><span class="token punctuation">;</span>
</code></pre></div><h5 id="切换数据库"><a href="#切换数据库" class="header-anchor">#</a> 切换数据库</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">--切换数据库</span>
<span class="token keyword">use</span> database_name<span class="token punctuation">;</span>
</code></pre></div><h5 id="创建数据库"><a href="#创建数据库" class="header-anchor">#</a> 创建数据库</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">/*创建数据库		
CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name
  [COMMENT database_comment]
  [LOCATION hdfs_path]
  [WITH DBPROPERTIES (property_name=property_value, ...)];
*/</span>
<span class="token keyword">create</span> <span class="token keyword">database</span> test<span class="token punctuation">;</span>
</code></pre></div><h5 id="删除数据库"><a href="#删除数据库" class="header-anchor">#</a> 删除数据库</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">/*
删除数据库	
DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE];	
*/</span>
<span class="token keyword">drop</span> <span class="token keyword">database</span> database_name<span class="token punctuation">;</span>
</code></pre></div><h4 id="数据库表的基本操作"><a href="#数据库表的基本操作" class="header-anchor">#</a> 数据库表的基本操作</h4> <h5 id="创建表的语法"><a href="#创建表的语法" class="header-anchor">#</a> 创建表的语法</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">/*
	创建表的操作
		基本语法：
		CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name    -- 			(Note: TEMPORARY available in Hive 0.14.0 and later)
  		[(col_name data_type [COMMENT col_comment], ... [constraint_specification])]
  		[COMMENT table_comment]
  		[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]
  		[CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] 				INTO num_buckets BUCKETS]
  		[SKEWED BY (col_name, col_name, ...)                  -- (Note: Available in Hive 			0.10.0 and later)]
     	ON ((col_value, col_value, ...), (col_value, col_value, ...), ...)
     	[STORED AS DIRECTORIES]
  		[
   			[ROW FORMAT row_format] 
   			[STORED AS file_format]
     		| STORED BY 'storage.handler.class.name' [WITH SERDEPROPERTIES (...)]  -- 				(Note: Available in Hive 0.6.0 and later)
  		]
  		[LOCATION hdfs_path]
  		[TBLPROPERTIES (property_name=property_value, ...)]   -- (Note: Available in Hive 			0.6.0 and later)
  		[AS select_statement];   -- (Note: Available in Hive 0.5.0 and later; not 					supported for external tables)
 
		CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name
  			LIKE existing_table_or_view_name
  		[LOCATION hdfs_path];
 		复杂数据类型
		data_type
  		 : primitive_type
  		 | array_type
  		 | map_type
  		 | struct_type
  		 | union_type  -- (Note: Available in Hive 0.7.0 and later)
 		基本数据类型
		primitive_type
 		 : TINYINT
 		 | SMALLINT
 		 | INT
 		 | BIGINT
 		 | BOOLEAN
 		 | FLOAT
 		 | DOUBLE
  		 | DOUBLE PRECISION -- (Note: Available in Hive 2.2.0 and later)
 		 | STRING
 		 | BINARY      -- (Note: Available in Hive 0.8.0 and later)
 		 | TIMESTAMP   -- (Note: Available in Hive 0.8.0 and later)
 		 | DECIMAL     -- (Note: Available in Hive 0.11.0 and later)
 		 | DECIMAL(precision, scale)  -- (Note: Available in Hive 0.13.0 and later)
 		 | DATE        -- (Note: Available in Hive 0.12.0 and later)
 		 | VARCHAR     -- (Note: Available in Hive 0.12.0 and later)
 		 | CHAR        -- (Note: Available in Hive 0.13.0 and later)
 
		array_type
 		 : ARRAY &lt; data_type &gt;
 
		map_type
 		 : MAP &lt; primitive_type, data_type &gt;
 
		struct_type
 		 : STRUCT &lt; col_name : data_type [COMMENT col_comment], ...&gt;
 
		union_type
  		 : UNIONTYPE &lt; data_type, data_type, ... &gt;  -- (Note: Available in Hive 0.7.0 and 			later)
 		行格式规范
		row_format
 		 : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS 				TERMINATED BY char]
 	       [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]
	       [NULL DEFINED AS char]   -- (Note: Available in Hive 0.13 and later)
  			| SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, 				property_name=property_value, ...)]
 		文件基本类型
		file_format:
 		 : SEQUENCEFILE
 		 | TEXTFILE    -- (Default, depending on hive.default.fileformat configuration)
 		 | RCFILE      -- (Note: Available in Hive 0.6.0 and later)
 		 | ORC         -- (Note: Available in Hive 0.11.0 and later)
 		 | PARQUET     -- (Note: Available in Hive 0.13.0 and later)
 		 | AVRO        -- (Note: Available in Hive 0.14.0 and later)
 		 | JSONFILE    -- (Note: Available in Hive 4.0.0 and later)
 		 | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname
 		表约束
		constraint_specification:
 		 : [, PRIMARY KEY (col_name, ...) DISABLE NOVALIDATE ]
 		   [, CONSTRAINT constraint_name FOREIGN KEY (col_name, ...) REFERENCES 					table_name(col_name, ...) DISABLE NOVALIDATE 
*/</span>
</code></pre></div><h5 id="创建普通hive表-不包含行定义格式"><a href="#创建普通hive表-不包含行定义格式" class="header-anchor">#</a> 创建普通hive表（不包含行定义格式）</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 创建普通hive表（不包含行定义格式）</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> psn
<span class="token punctuation">(</span>
	id <span class="token keyword">int</span><span class="token punctuation">,</span>
	name string<span class="token punctuation">,</span>
	likes array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span><span class="token punctuation">,</span>
	address map<span class="token operator">&lt;</span>string<span class="token punctuation">,</span>string<span class="token operator">&gt;</span>
<span class="token punctuation">)</span>
</code></pre></div><h5 id="创建自定义行格式的hive表"><a href="#创建自定义行格式的hive表" class="header-anchor">#</a> 创建自定义行格式的hive表</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 创建自定义行格式的hive表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> psn2
	<span class="token punctuation">(</span>
	id <span class="token keyword">int</span><span class="token punctuation">,</span>
	name string<span class="token punctuation">,</span>
	likes array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span><span class="token punctuation">,</span>
	address map<span class="token operator">&lt;</span>string<span class="token punctuation">,</span>string<span class="token operator">&gt;</span>
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span>
collection items <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'-'</span>
map <span class="token keyword">keys</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">':'</span><span class="token punctuation">;</span>
</code></pre></div><h5 id="创建默认分隔符的hive表-a、-b、-c"><a href="#创建默认分隔符的hive表-a、-b、-c" class="header-anchor">#</a> 创建默认分隔符的hive表（^A、^B、^C）</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 创建默认分隔符的hive表（^A、^B、^C）</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> psn3
<span class="token punctuation">(</span>
	id <span class="token keyword">int</span><span class="token punctuation">,</span>
	name string<span class="token punctuation">,</span>
	likes array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span><span class="token punctuation">,</span>
	address map<span class="token operator">&lt;</span>string<span class="token punctuation">,</span>string<span class="token operator">&gt;</span>
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\001'</span>
collection items <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\002'</span>
map <span class="token keyword">keys</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\003'</span><span class="token punctuation">;</span>
<span class="token comment">-- 或者</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> psn3
<span class="token punctuation">(</span>
	id <span class="token keyword">int</span><span class="token punctuation">,</span>
	name string<span class="token punctuation">,</span>
	likes array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span><span class="token punctuation">,</span>
	address map<span class="token operator">&lt;</span>string<span class="token punctuation">,</span>string<span class="token operator">&gt;</span>
<span class="token punctuation">)</span>
</code></pre></div><h5 id="创建hive的外部表"><a href="#创建hive的外部表" class="header-anchor">#</a> 创建hive的外部表</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 创建hive的外部表(需要添加external和location的关键字)</span>
<span class="token keyword">create</span> external <span class="token keyword">table</span> psn4
<span class="token punctuation">(</span>
	id <span class="token keyword">int</span><span class="token punctuation">,</span>
	name string<span class="token punctuation">,</span>
	likes array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span><span class="token punctuation">,</span>
	address map<span class="token operator">&lt;</span>string<span class="token punctuation">,</span>string<span class="token operator">&gt;</span>
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span>
collection items <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'-'</span>
map <span class="token keyword">keys</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">':'</span>
location <span class="token string">'/data'</span><span class="token punctuation">;</span>
<span class="token comment">/*
在之前创建的表都属于hive的内部表（psn,psn2,psn3）,而psn4属于hive的外部表，
内部表跟外部表的区别：
	1、hive内部表创建的时候数据存储在hive的默认存储目录中，外部表在创建的时候需要制定额外的目录
	2、hive内部表删除的时候，会将元数据和数据都删除，而外部表只会删除元数据，不会删除数据
应用场景:
	内部表:需要先创建表，然后向表中添加数据，适合做中间表的存储
	外部表：可以先创建表，再添加数据，也可以先有数据，再创建表，本质上是将hdfs的某一个目录的数据跟				hive的表关联映射起来，因此适合原始数据的存储，不会因为误操作将数据给删除掉
*/</span>	
</code></pre></div><h5 id="hive分区表-一张表拆分成多个目录"><a href="#hive分区表-一张表拆分成多个目录" class="header-anchor">#</a> Hive分区表：一张表拆分成多个目录</h5> <blockquote><p>hive的分区表：</p> <p><strong>hive默认将表的数据保存在某一个hdfs的存储目录下，当需要检索符合条件的某一部分数据的时候，需要全量遍历数据，io量比较大，效率比较低，因此可以采用分而治之的思想，将符合某些条件的数据放置在某一个目录，此时检索的时候只需要搜索指定目录即可，不需要全量遍历数据。</strong></p></blockquote> <h5 id="创建单分区表"><a href="#创建单分区表" class="header-anchor">#</a> 创建单分区表</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 创建单分区表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> psn5
<span class="token punctuation">(</span>
	id <span class="token keyword">int</span><span class="token punctuation">,</span>
	name string<span class="token punctuation">,</span>
	likes array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span><span class="token punctuation">,</span>
	address map<span class="token operator">&lt;</span>string<span class="token punctuation">,</span>string<span class="token operator">&gt;</span>
<span class="token punctuation">)</span>
partitioned <span class="token keyword">by</span><span class="token punctuation">(</span>gender string<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span>
collection items <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'-'</span>
map <span class="token keyword">keys</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">':'</span><span class="token punctuation">;</span>
</code></pre></div><h5 id="创建多分区表"><a href="#创建多分区表" class="header-anchor">#</a> 创建多分区表</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 创建多分区表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> psn6
<span class="token punctuation">(</span>
	id <span class="token keyword">int</span><span class="token punctuation">,</span>
	name string<span class="token punctuation">,</span>
	likes array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span><span class="token punctuation">,</span>
	address map<span class="token operator">&lt;</span>string<span class="token punctuation">,</span>string<span class="token operator">&gt;</span>
<span class="token punctuation">)</span>
partitioned <span class="token keyword">by</span><span class="token punctuation">(</span>gender string<span class="token punctuation">,</span>age <span class="token keyword">int</span><span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span>
collection items <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'-'</span>
map <span class="token keyword">keys</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">':'</span><span class="token punctuation">;</span>	
<span class="token comment">/*
注意：
	1、当创建完分区表之后，在保存数据的时候，会在hdfs目录中看到分区列会成为一个目录，以多级目录的形式存在
	2、当创建多分区表之后，插入数据的时候不可以只添加一个分区列，需要将所有的分区列都添加值
	3、多分区表在添加分区列的值得时候，与顺序无关，与分区表的分区列的名称相关，按照名称就行匹配
*/</span>	
</code></pre></div><h5 id="给分区表添加分区列的值"><a href="#给分区表添加分区列的值" class="header-anchor">#</a> 给分区表添加分区列的值</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 给分区表添加分区列的值</span>
<span class="token keyword">alter</span> <span class="token keyword">table</span> table_name <span class="token keyword">add</span> <span class="token keyword">partition</span><span class="token punctuation">(</span>col_name<span class="token operator">=</span>col_value<span class="token punctuation">)</span>

<span class="token comment">-- 注意：添加分区列的值的时候，如果定义的是多分区表，那么必须给所有的分区列都赋值</span>
</code></pre></div><h5 id="删除分区列的值"><a href="#删除分区列的值" class="header-anchor">#</a> 删除分区列的值</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 删除分区列的值</span>
<span class="token keyword">alter</span> <span class="token keyword">table</span> table_name <span class="token keyword">drop</span> <span class="token keyword">partition</span><span class="token punctuation">(</span>col_name<span class="token operator">=</span>col_value<span class="token punctuation">)</span>

<span class="token comment">-- 注意：删除分区列的值的时候，无论是单分区表还是多分区表，都可以将指定的分区进行删除</span>
</code></pre></div><h5 id="修复分区"><a href="#修复分区" class="header-anchor">#</a> 修复分区</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">/*
修复分区:
	在使用hive外部表的时候，可以先将数据上传到hdfs的某一个目录中，然后再创建外部表建立映射关系，如果在上传数据的时候，参考分区表的形式也创建了多级目录，那么此时创建完表之后，是查询不到数据的，原因是分区的元数据没有保存在mysql中，因此需要修复分区，将元数据同步更新到mysql中，此时才可以查询到元数据。具体操作如下：
*/</span>

<span class="token comment">-- 在hdfs创建目录并上传文件</span>
hdfs dfs <span class="token operator">-</span>mkdir <span class="token operator">/</span>msb
hdfs dfs <span class="token operator">-</span>mkdir <span class="token operator">/</span>msb<span class="token operator">/</span>age<span class="token operator">=</span><span class="token number">10</span>
hdfs dfs <span class="token operator">-</span>mkdir <span class="token operator">/</span>msb<span class="token operator">/</span>age<span class="token operator">=</span><span class="token number">20</span>
hdfs dfs <span class="token operator">-</span>put <span class="token operator">/</span>root<span class="token operator">/</span><span class="token keyword">data</span><span class="token operator">/</span><span class="token keyword">data</span> <span class="token operator">/</span>msb<span class="token operator">/</span>age<span class="token operator">=</span><span class="token number">10</span>
hdfs dfs <span class="token operator">-</span>put <span class="token operator">/</span>root<span class="token operator">/</span><span class="token keyword">data</span><span class="token operator">/</span><span class="token keyword">data</span> <span class="token operator">/</span>msb<span class="token operator">/</span>age<span class="token operator">=</span><span class="token number">20</span>

<span class="token comment">-- 创建外部表</span>
<span class="token keyword">create</span> external <span class="token keyword">table</span> psn7
<span class="token punctuation">(</span>
	id <span class="token keyword">int</span><span class="token punctuation">,</span>
	name string<span class="token punctuation">,</span>
	likes array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span><span class="token punctuation">,</span>
	address map<span class="token operator">&lt;</span>string<span class="token punctuation">,</span>string<span class="token operator">&gt;</span>
<span class="token punctuation">)</span>
partitioned <span class="token keyword">by</span><span class="token punctuation">(</span>age <span class="token keyword">int</span><span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span>
collection items <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'-'</span>
map <span class="token keyword">keys</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">':'</span>
location <span class="token string">'/msb'</span><span class="token punctuation">;</span>
<span class="token comment">-- 查询结果（没有数据）</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> psn7<span class="token punctuation">;</span>
<span class="token comment">-- 修复分区</span>
msck repair <span class="token keyword">table</span> psn7<span class="token punctuation">;</span>
<span class="token comment">-- 查询结果（有数据）</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> psn7<span class="token punctuation">;</span>

<span class="token comment">/*
问题：
	以上面的方式创建hive的分区表会存在问题，每次插入的数据都是人为指定分区列的值，我们更加希望能够根据记录中的某一个字段来判断将数据插入到哪一个分区目录下，此时利用我们上面的分区方式是无法完成操作的，需要使用动态分区来完成相关操作。
*/</span>
</code></pre></div><h5 id="hive动态分区"><a href="#hive动态分区" class="header-anchor">#</a> Hive动态分区</h5> <blockquote><p>hive的静态分区需要用户在插入数据的时候必须手动指定hive的分区字段值，但是这样的话会导致用户的操作复杂度提高，而且在使用的时候会导致数据只能插入到某一个指定分区，无法让数据散列分布，因此更好的方式是当数据在进行插入的时候，根据数据的某一个字段或某几个字段值动态的将数据插入到不同的目录中，此时，引入动态分区。</p></blockquote> <h6 id="hive的动态分区配置"><a href="#hive的动态分区配置" class="header-anchor">#</a> hive的动态分区配置</h6> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- hive设置hive动态分区开启</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
默认：<span class="token boolean">true</span>
<span class="token comment">-- hive的动态分区模式</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token operator">=</span>nostrict<span class="token punctuation">;</span>
默认：strict（至少有一个分区列是静态分区）
<span class="token comment">-- 每一个执行mr节点上，允许创建的动态分区的最大数量(100)</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>max<span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>pernode<span class="token punctuation">;</span>
<span class="token comment">-- 所有执行mr节点上，允许创建的所有动态分区的最大数量(1000)	</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>max<span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span>partitions<span class="token punctuation">;</span>
<span class="token comment">-- 所有的mr job允许创建的文件的最大数量(100000)	</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>max<span class="token punctuation">.</span>created<span class="token punctuation">.</span>files<span class="token punctuation">;</span>
</code></pre></div><h6 id="案例-加载数据"><a href="#案例-加载数据" class="header-anchor">#</a> 案例：加载数据</h6> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 从psn21表加载数据到psn22</span>
<span class="token keyword">from</span> psn21
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> psn22 <span class="token keyword">partition</span><span class="token punctuation">(</span>age<span class="token punctuation">,</span> sex<span class="token punctuation">)</span>
<span class="token keyword">select</span> id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">,</span> sex<span class="token punctuation">,</span> likes<span class="token punctuation">,</span> address distribute <span class="token keyword">by</span> age<span class="token punctuation">,</span> sex<span class="token punctuation">;</span>
</code></pre></div><h6 id="hive动态分区语法"><a href="#hive动态分区语法" class="header-anchor">#</a> hive动态分区语法</h6> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">--Hive extension (dynamic partition inserts):</span>
<span class="token keyword">INSERT</span> OVERWRITE <span class="token keyword">TABLE</span> tablename <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>partcol1<span class="token punctuation">[</span><span class="token operator">=</span>val1<span class="token punctuation">]</span><span class="token punctuation">,</span> partcol2<span class="token punctuation">[</span><span class="token operator">=</span>val2<span class="token punctuation">]</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> 		select_statement <span class="token keyword">FROM</span> from_statement<span class="token punctuation">;</span>
<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> <span class="token keyword">TABLE</span> tablename <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>partcol1<span class="token punctuation">[</span><span class="token operator">=</span>val1<span class="token punctuation">]</span><span class="token punctuation">,</span> partcol2<span class="token punctuation">[</span><span class="token operator">=</span>val2<span class="token punctuation">]</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> 			select_statement <span class="token keyword">FROM</span> from_statement<span class="token punctuation">;</span>
</code></pre></div><h5 id="hive分桶-可以把一个文件拆分成多个文件"><a href="#hive分桶-可以把一个文件拆分成多个文件" class="header-anchor">#</a> Hive分桶：可以把一个文件拆分成多个文件</h5> <blockquote><p>​	Bucketed tables are fantastic in that they allow much more efficient sampling than do non-bucketed tables, and they may later allow for time saving operations such as mapside joins. However, the bucketing specified at table creation is not enforced when the table is written to, and so it is possible for the table's metadata to advertise properties which are not upheld by the table's actual layout. This should obviously be avoided. Here's how to do it right。</p></blockquote> <p><strong>注意：</strong></p> <ol><li>Hive分桶表是对列值取hash值得方式，将不同数据放到不同文件中存储</li> <li>对于hive中每一个表、分区都可以进一步进行分桶</li> <li>由列的hash值除以桶的个数来决定每条数据划分在哪个桶中</li></ol> <p>**适用场景：**数据抽样（ sampling )</p> <h6 id="hive分桶的配置"><a href="#hive分桶的配置" class="header-anchor">#</a> Hive分桶的配置</h6> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 设置hive支持分桶</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>enforce<span class="token punctuation">.</span>bucketing<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token comment">-- 默认：false；设置为true之后，mr运行时会根据bucket的个数自动分配reduce task个数。（用户也可以通过mapred.reduce.tasks自己设置reduce任务个数，但分桶时不推荐使用）</span>
<span class="token comment">-- 注意：一次作业产生的桶（文件数量）和reduce task个数一致。</span>
</code></pre></div><h6 id="往分桶中加载数据"><a href="#往分桶中加载数据" class="header-anchor">#</a> 往分桶中加载数据</h6> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> bucket_table <span class="token keyword">select</span> <span class="token keyword">columns</span> <span class="token keyword">from</span> tbl<span class="token punctuation">;</span>

<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> bucket_table <span class="token keyword">select</span> <span class="token keyword">columns</span> <span class="token keyword">from</span> tbl<span class="token punctuation">;</span>
</code></pre></div><h6 id="hive分桶的抽样查询"><a href="#hive分桶的抽样查询" class="header-anchor">#</a> Hive分桶的抽样查询</h6> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 案例</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> bucket_table tablesample<span class="token punctuation">(</span>bucket <span class="token number">1</span> <span class="token keyword">out</span> <span class="token keyword">of</span> <span class="token number">4</span> <span class="token keyword">on</span> <span class="token keyword">columns</span><span class="token punctuation">)</span>
<span class="token comment">-- TABLESAMPLE语法：</span>
TABLESAMPLE<span class="token punctuation">(</span>BUCKET x <span class="token keyword">OUT</span> <span class="token keyword">OF</span> y<span class="token punctuation">)</span>
	x：表示从哪个bucket开始抽取数据
	y：必须为该表总bucket数的倍数或因子
</code></pre></div><h6 id="案例"><a href="#案例" class="header-anchor">#</a> 案例</h6> <blockquote><p>当表的总bucket数为32时
TABLESAMPLE(BUCKET 3 OUT OF 8)，抽取哪些数据？
32/8=4个桶（抽取的是桶的个数/y）
3、11、19、27（跳的是y的值）
共抽取4个bucket的数据，抽取第3、11、19、27个bucket的数据</p></blockquote> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> psn31<span class="token punctuation">(</span> id <span class="token keyword">INT</span><span class="token punctuation">,</span> name STRING<span class="token punctuation">,</span> age <span class="token keyword">INT</span><span class="token punctuation">)</span>
<span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">','</span><span class="token punctuation">;</span>
<span class="token comment">-- 测试数据</span>
<span class="token number">1</span><span class="token punctuation">,</span>tom<span class="token punctuation">,</span><span class="token number">11</span>
<span class="token number">2</span><span class="token punctuation">,</span>cat<span class="token punctuation">,</span><span class="token number">22</span>
<span class="token number">3</span><span class="token punctuation">,</span>dog<span class="token punctuation">,</span><span class="token number">33</span>
<span class="token number">4</span><span class="token punctuation">,</span>hive<span class="token punctuation">,</span><span class="token number">44</span>
<span class="token number">5</span><span class="token punctuation">,</span>hbase<span class="token punctuation">,</span><span class="token number">55</span>
<span class="token number">6</span><span class="token punctuation">,</span>mr<span class="token punctuation">,</span><span class="token number">66</span>
<span class="token number">7</span><span class="token punctuation">,</span>alice<span class="token punctuation">,</span><span class="token number">77</span>
<span class="token number">8</span><span class="token punctuation">,</span>scala<span class="token punctuation">,</span><span class="token number">88</span>

<span class="token comment">-- 创建分桶表</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> psnbucket<span class="token punctuation">(</span> id <span class="token keyword">INT</span><span class="token punctuation">,</span> name STRING<span class="token punctuation">,</span> age <span class="token keyword">INT</span><span class="token punctuation">)</span><span class="token keyword">CLUSTERED</span> <span class="token keyword">BY</span> <span class="token punctuation">(</span>age<span class="token punctuation">)</span> <span class="token keyword">INTO</span> <span class="token number">4</span> BUCKETSROW FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">','</span><span class="token punctuation">;</span>
<span class="token comment">-- 加载数据：</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> psnbucket <span class="token keyword">select</span> id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age <span class="token keyword">from</span> psn31<span class="token punctuation">;</span>
<span class="token comment">-- 抽样</span>
<span class="token keyword">select</span> id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age <span class="token keyword">from</span> psnbucket tablesample<span class="token punctuation">(</span>bucket <span class="token number">2</span> <span class="token keyword">out</span> <span class="token keyword">of</span> <span class="token number">4</span> <span class="token keyword">on</span> age<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h3 id="hive-dml"><a href="#hive-dml" class="header-anchor">#</a> Hive DML</h3> <h4 id="加载文件到表中"><a href="#加载文件到表中" class="header-anchor">#</a> 加载文件到表中</h4> <p><strong>Loading files into tables</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">/*
记载数据文件到某一张表中
语法：
	LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE tablename [PARTITION 		(partcol1=val1, partcol2=val2 ...)]
 
	LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE tablename [PARTITION 		(partcol1=val1, partcol2=val2 ...)] [INPUTFORMAT 'inputformat' SERDE 'serde']  (3.0 or later)
*/</span>
<span class="token comment">-- 加载本地数据到hive表</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/data/data'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> psn<span class="token punctuation">;</span><span class="token comment">--(/root/data/data指的是本地		linux目录)</span>
<span class="token comment">-- 加载hdfs数据文件到hive表</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> inpath <span class="token string">'/data/data'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> psn<span class="token punctuation">;</span><span class="token comment">--(/data/data指的是hdfs的目录)</span>
<span class="token comment">/*
注意：
	1、load操作不会对数据做任何的转换修改操作
	2、从本地linux load数据文件是复制文件的过程
	3、从hdfs load数据文件是移动文件的过程
	4、load操作也支持向分区表中load数据，只不过需要添加分区列的值
*/</span>
</code></pre></div><h4 id="把查询到的数据插入数据到hive的表中"><a href="#把查询到的数据插入数据到hive的表中" class="header-anchor">#</a> 把查询到的数据插入数据到Hive的表中</h4> <p><strong>Inserting data into Hive Tables from queries</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">/*
从查询语句中获取数据插入某张表
语法：
	Standard syntax:
	INSERT OVERWRITE TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...) 			[IF NOT EXISTS]] select_statement1 FROM from_statement;
	INSERT INTO TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)] 				select_statement1 FROM from_statement;

	Hive extension (multiple inserts):
	FROM from_statement
	INSERT OVERWRITE TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...) 			[IF NOT EXISTS]] select_statement1
	[INSERT OVERWRITE TABLE tablename2 [PARTITION ... [IF NOT EXISTS]] 							select_statement2]
	[INSERT INTO TABLE tablename2 [PARTITION ...] select_statement2] ...;
		FROM from_statement
	INSERT INTO TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)] 				select_statement1
	[INSERT INTO TABLE tablename2 [PARTITION ...] select_statement2]
	[INSERT OVERWRITE TABLE tablename2 [PARTITION ... [IF NOT EXISTS]] 							select_statement2] ...;

	Hive extension (dynamic partition inserts):
		INSERT OVERWRITE TABLE tablename PARTITION (partcol1[=val1], partcol2[=val2] 				...) select_statement FROM from_statement;
		INSERT INTO TABLE tablename PARTITION (partcol1[=val1], partcol2[=val2] ...) 				select_statement FROM from_statement;
*/</span>
<span class="token comment">-- 注意：这种方式插入数据的时候需要预先创建好结果表</span>
<span class="token comment">-- 从表中查询数据插入结果表</span>
<span class="token keyword">INSERT</span> OVERWRITE <span class="token keyword">TABLE</span> psn9 <span class="token keyword">SELECT</span> id<span class="token punctuation">,</span>name <span class="token keyword">FROM</span> psn
<span class="token comment">-- 从表中获取部分列插入到新表中</span>
<span class="token keyword">from</span> psn
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> psn9
<span class="token keyword">select</span> id<span class="token punctuation">,</span>name 
<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> psn10
<span class="token keyword">select</span> id
</code></pre></div><h4 id="把查询出的数据写到本地文件系统"><a href="#把查询出的数据写到本地文件系统" class="header-anchor">#</a> 把查询出的数据写到本地文件系统</h4> <p><strong>Writing data into the filesystem from queries</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">/*
将查询到的结果插入到文件系统中
语法：	
Standard syntax:
	INSERT OVERWRITE [LOCAL] DIRECTORY directory1
	[ROW FORMAT row_format] [STORED AS file_format] (Note: Only available starting 			with Hive 0.11.0)
	SELECT ... FROM ...

Hive extension (multiple inserts):
	FROM from_statement
	INSERT OVERWRITE [LOCAL] DIRECTORY directory1 select_statement1
	[INSERT OVERWRITE [LOCAL] DIRECTORY directory2 select_statement2] ... 
	row_format
	: DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS 			TERMINATED BY char]
	[MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]
	[NULL DEFINED AS char] (Note: Only available starting with Hive 0.13)
*/</span>
<span class="token comment">-- 注意：路径千万不要填写根目录，会把所有的数据文件都覆盖</span>
<span class="token comment">-- 将查询到的结果导入到hdfs文件系统中</span>
<span class="token keyword">insert</span> overwrite directory <span class="token string">'/result'</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> psn<span class="token punctuation">;</span>
<span class="token comment">-- 将查询的结果导入到本地文件系统中</span>
<span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/result'</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> psn<span class="token punctuation">;</span>
</code></pre></div><h4 id="使用insert-into-语句插入数据"><a href="#使用insert-into-语句插入数据" class="header-anchor">#</a> 使用insert into 语句插入数据</h4> <p><strong>Inserting values into tables from SQL</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">/*
使用传统关系型数据库的方式插入数据，效率较低
语法：
Standard Syntax:
	INSERT INTO TABLE tablename [PARTITION (partcol1[=val1], partcol2[=val2] ...)] 			VALUES values_row [, values_row ...]

Where values_row is:
	( value [, value ...] )
	where a value is either null or any valid SQL literal
*/</span>
<span class="token comment">-- 插入数据</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> psn <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'zhangsan'</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="数据更新和删除"><a href="#数据更新和删除" class="header-anchor">#</a> 数据更新和删除</h4> <blockquote><p>在官网中我们明确看到hive中是支持Update和Delete操作的，但是实际上，是需要事务的支持的，Hive对于事务的支持有很多的限制。因此，在使用hive的过程中，我们一般不会产生删除和更新的操作，如果你需要测试的话，参考下面如下配置：</p></blockquote> <p><img src="/images/transaction_limitations.png" alt="transaction_limitations"></p> <p><img src="/images/update.png" alt="update"></p> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token comment">&lt;!-- 在hive的hive-site.xml中添加如下配置：--&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.support.concurrency<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.enforce.bucketing<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.exec.dynamic.partition.mode<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>nonstrict<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.txn.manager<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.compactor.initiator.on<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.compactor.worker.threads<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><p><strong>执行测试</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 操作语句</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> test_trancaction <span class="token punctuation">(</span>user_id <span class="token keyword">Int</span><span class="token punctuation">,</span>name String<span class="token punctuation">)</span> <span class="token keyword">clustered</span> <span class="token keyword">by</span> <span class="token punctuation">(</span>user_id<span class="token punctuation">)</span> <span class="token keyword">into</span> <span class="token number">3</span> 			buckets stored <span class="token keyword">as</span> orc TBLPROPERTIES <span class="token punctuation">(</span><span class="token string">'transactional'</span><span class="token operator">=</span><span class="token string">'true'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> test_insert_test<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> 				  <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">','</span><span class="token punctuation">;</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> test_trancaction <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> test_insert_test<span class="token punctuation">;</span>
<span class="token keyword">update</span> test_trancaction <span class="token keyword">set</span> name<span class="token operator">=</span><span class="token string">'jerrick_up'</span> <span class="token keyword">where</span> id<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span>

<span class="token comment">-- 数据文件</span>
<span class="token number">1</span><span class="token punctuation">,</span>jerrick
<span class="token number">2</span><span class="token punctuation">,</span>tom
<span class="token number">3</span><span class="token punctuation">,</span>jerry
<span class="token number">4</span><span class="token punctuation">,</span>lily
<span class="token number">5</span><span class="token punctuation">,</span>hanmei
<span class="token number">6</span><span class="token punctuation">,</span>limlei
<span class="token number">7</span><span class="token punctuation">,</span>lucky
</code></pre></div><h3 id="hive-serde"><a href="#hive-serde" class="header-anchor">#</a> Hive Serde</h3> <blockquote><p>Hive Serde用来做序列化和反序列化，构建在数据存储和执行引擎之间，对两者实现解耦</p></blockquote> <h4 id="应用场景"><a href="#应用场景" class="header-anchor">#</a> 应用场景</h4> <ol><li><p>hive主要用来存储结构化数据，如果结构化数据存储的格式嵌套比较复杂的时候，可以使用serde的方式，利用正则表达式匹配的方法来读取数据，例如，表字段如下：id,name,map&lt;string,array&lt;map&lt;string,string&gt;&gt;&gt;</p></li> <li><p>当读取数据的时候，数据的某些特殊格式不希望显示在数据中，如：</p> <p>192.168.57.4 - - [29/Feb/2019:18:14:35 +0800] &quot;GET /bg-upper.png HTTP/1.1&quot; 304 -</p> <p>不希望数据显示的时候包含[]或者&quot;&quot;,此时可以考虑使用serde的方式</p></li></ol> <h4 id="语法规则"><a href="#语法规则" class="header-anchor">#</a> 语法规则</h4> <div class="language-sql extra-class"><pre class="language-sql"><code>row_format
: DELIMITED 
  <span class="token punctuation">[</span><span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token keyword">char</span> <span class="token punctuation">[</span><span class="token keyword">ESCAPED</span> <span class="token keyword">BY</span> <span class="token keyword">char</span><span class="token punctuation">]</span><span class="token punctuation">]</span> 
  <span class="token punctuation">[</span>COLLECTION ITEMS <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token keyword">char</span><span class="token punctuation">]</span> 
  <span class="token punctuation">[</span>MAP <span class="token keyword">KEYS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token keyword">char</span><span class="token punctuation">]</span> 
  <span class="token punctuation">[</span><span class="token keyword">LINES</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token keyword">char</span><span class="token punctuation">]</span> 
: SERDE serde_name <span class="token punctuation">[</span><span class="token keyword">WITH</span> SERDEPROPERTIES <span class="token punctuation">(</span>property_name<span class="token operator">=</span>property_value<span class="token punctuation">,</span> property_name<span class="token operator">=</span>property_value<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre></div><h4 id="应用案例"><a href="#应用案例" class="header-anchor">#</a> 应用案例</h4> <h5 id="数据文件"><a href="#数据文件" class="header-anchor">#</a> 数据文件</h5> <div class="language- extra-class"><pre class="language-text"><code>192.168.57.4 - - [29/Feb/2019:18:14:35 +0800] &quot;GET /bg-upper.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:35 +0800] &quot;GET /bg-nav.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:35 +0800] &quot;GET /asf-logo.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:35 +0800] &quot;GET /bg-button.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:35 +0800] &quot;GET /bg-middle.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET / HTTP/1.1&quot; 200 11217
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET / HTTP/1.1&quot; 200 11217
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET /tomcat.css HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET /tomcat.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET /asf-logo.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET /bg-middle.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET /bg-button.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET /bg-nav.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET /bg-upper.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET / HTTP/1.1&quot; 200 11217
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET /tomcat.css HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET /tomcat.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET / HTTP/1.1&quot; 200 11217
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET /tomcat.css HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET /tomcat.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET /bg-button.png HTTP/1.1&quot; 304 -
192.168.57.4 - - [29/Feb/2019:18:14:36 +0800] &quot;GET /bg-upper.png HTTP/1.1&quot; 304 -
</code></pre></div><h5 id="基本操作"><a href="#基本操作" class="header-anchor">#</a> 基本操作</h5> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 创建表</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> logtbl <span class="token punctuation">(</span>
	host STRING<span class="token punctuation">,</span>
	<span class="token keyword">identity</span> STRING<span class="token punctuation">,</span>
	t_user STRING<span class="token punctuation">,</span>
	<span class="token keyword">time</span> STRING<span class="token punctuation">,</span>
	request STRING<span class="token punctuation">,</span>
	referer STRING<span class="token punctuation">,</span>
	agent STRING<span class="token punctuation">)</span>
  <span class="token keyword">ROW</span> FORMAT SERDE <span class="token string">'org.apache.hadoop.hive.serde2.RegexSerDe'</span>
  <span class="token keyword">WITH</span> SERDEPROPERTIES <span class="token punctuation">(</span>
	<span class="token string">&quot;input.regex&quot;</span> <span class="token operator">=</span> <span class="token string">&quot;([^ ]*) ([^ ]*) ([^ ]*) \\[(.*)\\] \&quot;(.*)\&quot; (-|[0-9]*) (-|[0-		9]*)&quot;</span>
  <span class="token punctuation">)</span>
  STORED <span class="token keyword">AS</span> TEXTFILE<span class="token punctuation">;</span>
<span class="token comment">-- 加载数据</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/data/log'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> logtbl<span class="token punctuation">;</span>
<span class="token comment">-- 查询操作</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> logtbl<span class="token punctuation">;</span>
<span class="token comment">-- 数据显示如下（不包含[]和&quot;）</span>
<span class="token number">192.168</span><span class="token number">.57</span><span class="token number">.4</span>	<span class="token operator">-</span>	<span class="token operator">-</span>	<span class="token number">29</span><span class="token operator">/</span>Feb<span class="token operator">/</span><span class="token number">2019</span>:<span class="token number">18</span>:<span class="token number">14</span>:<span class="token number">35</span> <span class="token operator">+</span><span class="token number">0800</span>	GET <span class="token operator">/</span>bg<span class="token operator">-</span>upper<span class="token punctuation">.</span>png HTTP<span class="token operator">/</span><span class="token number">1.1</span>	<span class="token number">304</span>	<span class="token operator">-</span>
<span class="token number">192.168</span><span class="token number">.57</span><span class="token number">.4</span>	<span class="token operator">-</span>	<span class="token operator">-</span>	<span class="token number">29</span><span class="token operator">/</span>Feb<span class="token operator">/</span><span class="token number">2019</span>:<span class="token number">18</span>:<span class="token number">14</span>:<span class="token number">35</span> <span class="token operator">+</span><span class="token number">0800</span>	GET <span class="token operator">/</span>bg<span class="token operator">-</span>nav<span class="token punctuation">.</span>png HTTP<span class="token operator">/</span><span class="token number">1.1</span>	<span class="token number">304</span>	<span class="token operator">-</span>
<span class="token number">192.168</span><span class="token number">.57</span><span class="token number">.4</span>	<span class="token operator">-</span>	<span class="token operator">-</span>	<span class="token number">29</span><span class="token operator">/</span>Feb<span class="token operator">/</span><span class="token number">2019</span>:<span class="token number">18</span>:<span class="token number">14</span>:<span class="token number">35</span> <span class="token operator">+</span><span class="token number">0800</span>	GET <span class="token operator">/</span>asf<span class="token operator">-</span>logo<span class="token punctuation">.</span>png HTTP<span class="token operator">/</span><span class="token number">1.1</span>	<span class="token number">304</span>	<span class="token operator">-</span>
<span class="token number">192.168</span><span class="token number">.57</span><span class="token number">.4</span>	<span class="token operator">-</span>	<span class="token operator">-</span>	<span class="token number">29</span><span class="token operator">/</span>Feb<span class="token operator">/</span><span class="token number">2019</span>:<span class="token number">18</span>:<span class="token number">14</span>:<span class="token number">35</span> <span class="token operator">+</span><span class="token number">0800</span>	GET <span class="token operator">/</span>bg<span class="token operator">-</span>button<span class="token punctuation">.</span>png HTTP<span class="token operator">/</span><span class="token number">1.1</span>	<span class="token number">304</span>	<span class="token operator">-</span>
<span class="token number">192.168</span><span class="token number">.57</span><span class="token number">.4</span>	<span class="token operator">-</span>	<span class="token operator">-</span>	<span class="token number">29</span><span class="token operator">/</span>Feb<span class="token operator">/</span><span class="token number">2019</span>:<span class="token number">18</span>:<span class="token number">14</span>:<span class="token number">35</span> <span class="token operator">+</span><span class="token number">0800</span>	GET <span class="token operator">/</span>bg<span class="token operator">-</span>middle<span class="token punctuation">.</span>png HTTP<span class="token operator">/</span><span class="token number">1.1</span>	<span class="token number">304</span>	<span class="token operator">-</span>
</code></pre></div><h2 id="hiveserver2"><a href="#hiveserver2" class="header-anchor">#</a> HiveServer2</h2> <h3 id="pom依赖"><a href="#pom依赖" class="header-anchor">#</a> pom依赖</h3> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hive/hive-jdbc --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hive<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hive-jdbc<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.3.6<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><h3 id="jdbc访问"><a href="#jdbc访问" class="header-anchor">#</a> jdbc访问</h3> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">try</span> <span class="token punctuation">{</span>
    <span class="token class-name">Class</span><span class="token punctuation">.</span><span class="token function">forName</span><span class="token punctuation">(</span><span class="token string">&quot;org.apache.hive.jdbc.HiveDriver&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ClassNotFoundException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
<span class="token class-name">Connection</span> conn <span class="token operator">=</span> <span class="token class-name">DriverManager</span><span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span><span class="token string">&quot;jdbc:hive2://node04:10000/default&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Statement</span> stmt <span class="token operator">=</span> conn<span class="token punctuation">.</span><span class="token function">createStatement</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">String</span> sql <span class="token operator">=</span> <span class="token string">&quot;select * from psn limit 5&quot;</span><span class="token punctuation">;</span>
<span class="token class-name">ResultSet</span> res <span class="token operator">=</span> stmt<span class="token punctuation">.</span><span class="token function">executeQuery</span><span class="token punctuation">(</span>sql<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">while</span> <span class="token punctuation">(</span>res<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>res<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;-&quot;</span> <span class="token operator">+</span> res<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre></div><h2 id="hive函数"><a href="#hive函数" class="header-anchor">#</a> Hive函数</h2> <blockquote><p>官方地址：</p> <div class="language-http extra-class"><pre class="language-http"><code><span class="token header"><span class="token header-name keyword">https</span><span class="token punctuation">:</span><span class="token header-value">//cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF</span></span>
</code></pre></div></blockquote> <p>Hive中提供了非常丰富的运算符和内置函数支撑，具体操作如下：</p> <h3 id="内置运算符"><a href="#内置运算符" class="header-anchor">#</a> 内置运算符</h3> <h4 id="关系运算符"><a href="#关系运算符" class="header-anchor">#</a> 关系运算符</h4> <table><thead><tr><th>运算符</th> <th>类型</th> <th>说明</th></tr></thead> <tbody><tr><td>A = B</td> <td>所有原始类型</td> <td>如果A与B相等,返回TRUE,否则返回FALSE</td></tr> <tr><td>A == B</td> <td>无</td> <td>失败，因为无效的语法。 SQL使用”=”，不使用”==”。</td></tr> <tr><td>A &lt;&gt; B</td> <td>所有原始类型</td> <td>如果A不等于B返回TRUE,否则返回FALSE。<br>如果A或B值为”NULL”，结果返回”NULL”。</td></tr> <tr><td>A &lt; B</td> <td>所有原始类型</td> <td>如果A小于B返回TRUE,否则返回FALSE。<br>如果A或B值为”NULL”，结果返回”NULL”。</td></tr> <tr><td>A &lt;= B</td> <td>所有原始类型</td> <td>如果A小于等于B返回TRUE,否则返回FALSE。<br>如果A或B值为”NULL”，结果返回”NULL”。</td></tr> <tr><td>A &gt; B</td> <td>所有原始类型</td> <td>如果A大于B返回TRUE,否则返回FALSE。<br>如果A或B值为”NULL”，结果返回”NULL”。</td></tr> <tr><td>A &gt;= B</td> <td>所有原始类型</td> <td>如果A大于等于B返回TRUE,否则返回FALSE。<br>如果A或B值为”NULL”，结果返回”NULL”。</td></tr> <tr><td>A IS NULL</td> <td>所有类型</td> <td>如果A值为”NULL”，返回TRUE,否则返回FALSE</td></tr> <tr><td>A IS NOT NULL</td> <td>所有类型</td> <td>如果A值不为”NULL”，返回TRUE,否则返回FALSE</td></tr> <tr><td>A LIKE B</td> <td>字符串</td> <td>如果A或B值为”NULL”，结果返回”NULL”。<br>字符串A与B通过sql进行匹配，<br>如果相符返回TRUE，不符返回FALSE。<br>B字符串中的”<em>”代表任一字符，”%”则代表多个任意字符。<br>例如：<br>(‘foobar’ like ‘foo’)返回FALSE，<br>(‘foobar’ like ‘foo</em> _ _’或者 ‘foobar’ like ‘foo%’)则返回TURE</td></tr> <tr><td>A RLIKE B</td> <td>字符串</td> <td>如果A或B值为”NULL”，结果返回”NULL”。<br>字符串A与B通过java进行匹配，<br>如果相符返回TRUE，不符返回FALSE。<br>例如：<br>(‘foobar’ rlike ‘foo’)返回FALSE，<br>(’foobar’ rlike ‘^f.*r$’)返回TRUE。</td></tr> <tr><td>A REGEXP B</td> <td>字符串</td> <td>与RLIKE相同。</td></tr></tbody></table> <h4 id="算数运算符"><a href="#算数运算符" class="header-anchor">#</a> 算数运算符</h4> <table><thead><tr><th>运算符</th> <th>类型</th> <th>说明</th></tr></thead> <tbody><tr><td>A + B</td> <td>所有数字类型</td> <td>A和B相加。结果的与操作数值有共同类型。<br>例如每一个整数是一个浮点数，浮点数包含整数。<br>所以，一个浮点数和一个整数相加结果也是一个浮点数。</td></tr> <tr><td>A – B</td> <td>所有数字类型</td> <td>A和B相减。结果的与操作数值有共同类型。</td></tr> <tr><td>A * B</td> <td>所有数字类型</td> <td>A和B相乘，结果的与操作数值有共同类型。<br>需要说明的是，如果乘法造成溢出，将选择更高的类型。</td></tr> <tr><td>A / B</td> <td>所有数字类型</td> <td>A和B相除，结果是一个double（双精度）类型的结果。</td></tr> <tr><td>A % B</td> <td>所有数字类型</td> <td>A除以B余数与操作数值有共同类型。</td></tr> <tr><td>A &amp; B</td> <td>所有数字类型</td> <td>运算符查看两个参数的二进制表示法的值，并执行按位”与”操作。<br>两个表达式的一位均为1时，则结果的该位为 1。否则，结果的该位为 0。</td></tr> <tr><td>A|B</td> <td>所有数字类型</td> <td>运算符查看两个参数的二进制表示法的值，并执行按位”或”操作。<br>只要任一表达式的一位为 1，则结果的该位为 1。否则，结果的该位为 0。</td></tr> <tr><td>A ^ B</td> <td>所有数字类型</td> <td>运算符查看两个参数的二进制表示法的值，并执行按位”异或”操作。<br>当且仅当只有一个表达式的某位上为 1 时，结果的该位才为 1。否则结果的该位为 0。</td></tr> <tr><td>~A</td> <td>所有数字类型</td> <td>对一个表达式执行按位”非”（取反）。</td></tr></tbody></table> <h4 id="逻辑运算符"><a href="#逻辑运算符" class="header-anchor">#</a> 逻辑运算符</h4> <table><thead><tr><th>运算符</th> <th>类型</th> <th>说明</th></tr></thead> <tbody><tr><td>A AND B</td> <td>布尔值</td> <td>A和B同时正确时,返回TRUE,否则FALSE。如果A或B值为NULL，返回NULL。</td></tr> <tr><td>A &amp;&amp; B</td> <td>布尔值</td> <td>与”A AND B”相同</td></tr> <tr><td>A OR B</td> <td>布尔值</td> <td>A或B正确,或两者同时正确返返回TRUE,否则FALSE。如果A和B值同时为NULL，返回NULL。</td></tr> <tr><td>A | B</td> <td>布尔值</td> <td>与”A OR B”相同</td></tr> <tr><td>NOT A</td> <td>布尔值</td> <td>如果A为NULL或错误的时候返回TURE，否则返回FALSE。</td></tr> <tr><td>! A</td> <td>布尔值</td> <td>与”NOT A”相同</td></tr></tbody></table> <h4 id="复杂类型函数"><a href="#复杂类型函数" class="header-anchor">#</a> 复杂类型函数</h4> <table><thead><tr><th>函数</th> <th>类型</th> <th>说明</th></tr></thead> <tbody><tr><td>map</td> <td>(key1, value1, key2, value2, …)</td> <td>通过指定的键/值对，创建一个map。</td></tr> <tr><td>struct</td> <td>(val1, val2, val3, …)</td> <td>通过指定的字段值，创建一个结构。结构字段名称将COL1，COL2，…</td></tr> <tr><td>array</td> <td>(val1, val2, …)</td> <td>通过指定的元素，创建一个数组。</td></tr></tbody></table> <h4 id="对复杂函数的操作"><a href="#对复杂函数的操作" class="header-anchor">#</a> 对复杂函数的操作</h4> <table><thead><tr><th>函数</th> <th>类型</th> <th>说明</th></tr></thead> <tbody><tr><td>A[n]</td> <td>A是一个数组，n为int型</td> <td>返回数组A的第n个元素，第一个元素的索引为0。<br>如果A数组为['foo','bar']，则A[0]返回’foo’和A[1]返回”bar”。</td></tr> <tr><td>M[key]</td> <td>M是Map&lt;K, V&gt;，关键K型</td> <td>返回关键值对应的值，<br>例如<br>mapM为 {‘f’ -&gt; ‘foo’, ‘b’ -&gt; ‘bar’, ‘all’ -&gt; ‘foobar’}，<br>则M['all'] 返回’foobar’。</td></tr> <tr><td>S.x</td> <td>S为struct</td> <td>返回结构x字符串在结构S中的存储位置。<br>如 <br>foobar {int foo, int bar} foobar.foo的领域中存储的整数。</td></tr></tbody></table> <h3 id="内置函数"><a href="#内置函数" class="header-anchor">#</a> 内置函数</h3> <h4 id="数学函数"><a href="#数学函数" class="header-anchor">#</a> 数学函数</h4> <table><thead><tr><th>返回类型</th> <th>函数</th> <th>说明</th></tr></thead> <tbody><tr><td>BIGINT</td> <td>round(double a)</td> <td>四舍五入</td></tr> <tr><td>DOUBLE</td> <td>round(double a, int d)</td> <td>小数部分d位之后数字四舍五入，例如round(21.263,2),返回21.26</td></tr> <tr><td>BIGINT</td> <td>floor(double a)</td> <td>对给定数据进行向下舍入最接近的整数。例如floor(21.2),返回21。</td></tr> <tr><td>BIGINT</td> <td>ceil(double a), ceiling(double a)</td> <td>将参数向上舍入为最接近的整数。例如ceil(21.2),返回23.</td></tr> <tr><td>double</td> <td>rand(), rand(int seed)</td> <td>返回大于或等于0且小于1的平均分布随机数（依重新计算而变）</td></tr> <tr><td>double</td> <td>exp(double a)</td> <td>返回e的n次方</td></tr> <tr><td>double</td> <td>ln(double a)</td> <td>返回给定数值的自然对数</td></tr> <tr><td>double</td> <td>log10(double a)</td> <td>返回给定数值的以10为底自然对数</td></tr> <tr><td>double</td> <td>log2(double a)</td> <td>返回给定数值的以2为底自然对数</td></tr> <tr><td>double</td> <td>log(double base, double a)</td> <td>返回给定底数及指数返回自然对数</td></tr> <tr><td>double</td> <td>pow(double a, double p) power(double a, double p)</td> <td>返回某数的乘幂</td></tr> <tr><td>double</td> <td>sqrt(double a)</td> <td>返回数值的平方根</td></tr> <tr><td>string</td> <td>bin(BIGINT a)</td> <td>返回二进制格式</td></tr> <tr><td>string</td> <td>hex(BIGINT a) hex(string a)</td> <td>将整数或字符转换为十六进制格式</td></tr> <tr><td>string</td> <td>unhex(string a)</td> <td>十六进制字符转换由数字表示的字符。</td></tr> <tr><td>string</td> <td>conv(BIGINT num, int from_base, int to_base)</td> <td>将 指定数值，由原来的度量体系转换为指定的试题体系。<br>例如CONV(‘a’,16,2),返回。<br>参考：’1010′ http://dev.mysql.com/doc/refman/5.0/en/mathematical-functions.html#function_conv</td></tr> <tr><td>double</td> <td>abs(double a)</td> <td>取绝对值</td></tr> <tr><td>int double</td> <td>pmod(int a, int b) pmod(double a, double b)</td> <td>返回a除b的余数的绝对值</td></tr> <tr><td>double</td> <td>sin(double a)</td> <td>返回给定角度的正弦值</td></tr> <tr><td>double</td> <td>asin(double a)</td> <td>返回x的反正弦，即是X。如果X是在-1到1的正弦值，返回NULL。</td></tr> <tr><td>double</td> <td>cos(double a)</td> <td>返回余弦</td></tr> <tr><td>double</td> <td>acos(double a)</td> <td>返回X的反余弦，即余弦是X，，如果-1&lt;= A &lt;= 1，否则返回null.</td></tr> <tr><td>int double</td> <td>positive(int a) positive(double a)</td> <td>返回A的值，例如positive(2)，返回2。</td></tr> <tr><td>int double</td> <td>negative(int a) negative(double a)</td> <td>返回A的相反数，例如negative(2),返回-2。</td></tr></tbody></table> <h4 id="收集函数"><a href="#收集函数" class="header-anchor">#</a> 收集函数</h4> <table><thead><tr><th>返回类型</th> <th>函数</th> <th>说明</th></tr></thead> <tbody><tr><td>int</td> <td>size(Map&lt;K.V&gt;)</td> <td>返回的map类型的元素的数量</td></tr> <tr><td>int</td> <td>size(Array<T>)</T></td> <td>返回数组类型的元素数量</td></tr></tbody></table> <h4 id="类型转换函数"><a href="#类型转换函数" class="header-anchor">#</a> 类型转换函数</h4> <table><thead><tr><th>返回类型</th> <th>函数</th> <th>说明</th></tr></thead> <tbody><tr><td>指定 “type”</td> <td>cast(expr as <type>)</type></td> <td>类型转换。例如将字符”1″转换为整数:cast(’1′ as bigint)，如果转换失败返回NULL。</td></tr></tbody></table> <h4 id="日期函数"><a href="#日期函数" class="header-anchor">#</a> 日期函数</h4> <table><thead><tr><th>返回类型</th> <th>函数</th> <th>说明</th></tr></thead> <tbody><tr><td>string</td> <td>from_unixtime(bigint unixtime[, string format])</td> <td>UNIX_TIMESTAMP参数表示返回一个值’YYYY- MM – DD HH：MM：SS’或YYYYMMDDHHMMSS.uuuuuu格式，这取决于是否是在一个字符串或数字语境中使用的功能。该值表示在当前的时区。</td></tr> <tr><td>bigint</td> <td>unix_timestamp()</td> <td>如果不带参数的调用，返回一个Unix时间戳（从’1970- 01 – 0100:00:00′到现在的UTC秒数）为无符号整数。</td></tr> <tr><td>bigint</td> <td>unix_timestamp(string date)</td> <td>指定日期参数调用UNIX_TIMESTAMP（），它返回参数值’1970- 01 – 0100:00:00′到指定日期的秒数。</td></tr> <tr><td>bigint</td> <td>unix_timestamp(string date, string pattern)</td> <td>指定时间输入格式，返回到1970年秒数：unix_timestamp(’2009-03-20′, ‘yyyy-MM-dd’) = 1237532400</td></tr> <tr><td>string</td> <td>to_date(string timestamp)</td> <td>返回时间中的年月日： to_date(“1970-01-01 00:00:00″) = “1970-01-01″</td></tr> <tr><td>string</td> <td>to_dates(string date)</td> <td>给定一个日期date，返回一个天数（0年以来的天数）</td></tr> <tr><td>int</td> <td>year(string date)</td> <td>返回指定时间的年份，范围在1000到9999，或为”零”日期的0。</td></tr> <tr><td>int</td> <td>month(string date)</td> <td>返回指定时间的月份，范围为1至12月，或0一个月的一部分，如’0000-00-00′或’2008-00-00′的日期。</td></tr> <tr><td>int</td> <td>day(string date) dayofmonth(date)</td> <td>返回指定时间的日期</td></tr> <tr><td>int</td> <td>hour(string date)</td> <td>返回指定时间的小时，范围为0到23。</td></tr> <tr><td>int</td> <td>minute(string date)</td> <td>返回指定时间的分钟，范围为0到59。</td></tr> <tr><td>int</td> <td>second(string date)</td> <td>返回指定时间的秒，范围为0到59。</td></tr> <tr><td>int</td> <td>weekofyear(string date)</td> <td>返回指定日期所在一年中的星期号，范围为0到53。</td></tr> <tr><td>int</td> <td>datediff(string enddate, string startdate)</td> <td>两个时间参数的日期之差。</td></tr> <tr><td>int</td> <td>date_add(string startdate, int days)</td> <td>给定时间，在此基础上加上指定的时间段。</td></tr> <tr><td>int</td> <td>date_sub(string startdate, int days)</td> <td>给定时间，在此基础上减去指定的时间段。</td></tr></tbody></table> <h4 id="条件函数"><a href="#条件函数" class="header-anchor">#</a> 条件函数</h4> <table><thead><tr><th>返回类型</th> <th>函数</th> <th>说明</th></tr></thead> <tbody><tr><td>T</td> <td>if(boolean testCondition, T valueTrue, T valueFalseOrNull)</td> <td>判断是否满足条件，如果满足返回一个值，如果不满足则返回另一个值。</td></tr> <tr><td>T</td> <td>COALESCE(T v1, T v2, …)</td> <td>返回一组数据中，第一个不为NULL的值，如果均为NULL,返回NULL。</td></tr> <tr><td>T</td> <td>CASE a WHEN b THEN c [WHEN d THEN e]* [ELSE f] END</td> <td>当a=b时,返回c；当a=d时，返回e，否则返回f。</td></tr> <tr><td>T</td> <td>CASE WHEN a THEN b [WHEN c THEN d]* [ELSE e] END</td> <td>当值为a时返回b,当值为c时返回d。否则返回e。</td></tr></tbody></table> <h4 id="字符函数"><a href="#字符函数" class="header-anchor">#</a> 字符函数</h4> <table><thead><tr><th>返回类型</th> <th>函数</th> <th>说明</th></tr></thead> <tbody><tr><td>int</td> <td>length(string A)</td> <td>返回字符串的长度</td></tr> <tr><td>string</td> <td>reverse(string A)</td> <td>返回倒序字符串</td></tr> <tr><td>string</td> <td>concat(string A, string B…)</td> <td>连接多个字符串，合并为一个字符串，可以接受任意数量的输入字符串</td></tr> <tr><td>string</td> <td>concat_ws(string SEP, string A, string B…)</td> <td>链接多个字符串，字符串之间以指定的分隔符分开。</td></tr> <tr><td>string</td> <td>substr(string A, int start) substring(string A, int start)</td> <td>从文本字符串中指定的起始位置后的字符。</td></tr> <tr><td>string</td> <td>substr(string A, int start, int len) substring(string A, int start, int len)</td> <td>从文本字符串中指定的位置指定长度的字符。</td></tr> <tr><td>string</td> <td>upper(string A) ucase(string A)</td> <td>将文本字符串转换成字母全部大写形式</td></tr> <tr><td>string</td> <td>lower(string A) lcase(string A)</td> <td>将文本字符串转换成字母全部小写形式</td></tr> <tr><td>string</td> <td>trim(string A)</td> <td>删除字符串两端的空格，字符之间的空格保留</td></tr> <tr><td>string</td> <td>ltrim(string A)</td> <td>删除字符串左边的空格，其他的空格保留</td></tr> <tr><td>string</td> <td>rtrim(string A)</td> <td>删除字符串右边的空格，其他的空格保留</td></tr> <tr><td>string</td> <td>regexp_replace(string A, string B, string C)</td> <td>字符串A中的B字符被C字符替代</td></tr> <tr><td>string</td> <td>regexp_extract(string subject, string pattern, int index)</td> <td>通过下标返回正则表达式指定的部分。regexp_extract(‘foothebar’, ‘foo(.*?)(bar)’, 2) returns ‘bar.’</td></tr> <tr><td>string</td> <td>parse_url(string urlString, string partToExtract [, string keyToExtract])</td> <td>返回URL指定的部分。parse_url(‘http://facebook.com/path1/p.php?k1=v1&amp;k2=v2#Ref1′, ‘HOST’) 返回：’facebook.com’</td></tr> <tr><td>string</td> <td>get_json_object(string json_string, string path)</td> <td>select a.timestamp, get_json_object(a.appevents, ‘$.eventid’), get_json_object(a.appenvets, ‘$.eventname’) from log a;</td></tr> <tr><td>string</td> <td>space(int n)</td> <td>返回指定数量的空格</td></tr> <tr><td>string</td> <td>repeat(string str, int n)</td> <td>重复N次字符串</td></tr> <tr><td>int</td> <td>ascii(string str)</td> <td>返回字符串中首字符的数字值</td></tr> <tr><td>string</td> <td>lpad(string str, int len, string pad)</td> <td>返回指定长度的字符串，给定字符串长度小于指定长度时，由指定字符从左侧填补。</td></tr> <tr><td>string</td> <td>rpad(string str, int len, string pad)</td> <td>返回指定长度的字符串，给定字符串长度小于指定长度时，由指定字符从右侧填补。</td></tr> <tr><td>array</td> <td>split(string str, string pat)</td> <td>将字符串转换为数组。</td></tr> <tr><td>int</td> <td>find_in_set(string str, string strList)</td> <td>返回字符串str第一次在strlist出现的位置。如果任一参数为NULL,返回NULL；如果第一个参数包含逗号，返回0。</td></tr> <tr><td>array&lt;array<string>&gt;</string></td> <td>sentences(string str, string lang, string locale)</td> <td>将字符串中内容按语句分组，每个单词间以逗号分隔，最后返回数组。 例如sentences(‘Hello there! How are you?’) 返回：( (“Hello”, “there”), (“How”, “are”, “you”) )</td></tr> <tr><td>array&lt;struct&lt;string,double&gt;&gt;</td> <td>ngrams(array&lt;array<string>&gt;, int N, int K, int pf)</string></td> <td>SELECT ngrams(sentences(lower(tweet)), 2, 100 [, 1000]) FROM twitter;</td></tr> <tr><td>array&lt;struct&lt;string,double&gt;&gt;</td> <td>context_ngrams(array&lt;array<string>&gt;, array<string>, int K, int pf)</string></string></td> <td>SELECT context_ngrams(sentences(lower(tweet)), array(null,null), 100, [, 1000]) FROM twitter;</td></tr></tbody></table> <h3 id="内置的聚合函数-udaf"><a href="#内置的聚合函数-udaf" class="header-anchor">#</a> 内置的聚合函数（UDAF）</h3> <table><thead><tr><th>返回类型</th> <th>函数</th> <th>说明</th></tr></thead> <tbody><tr><td>bigint</td> <td>count(*) , count(expr), count(DISTINCT expr[, expr_., expr_.])</td> <td>返回记录条数。</td></tr> <tr><td>double</td> <td>sum(col), sum(DISTINCT col)</td> <td>求和</td></tr> <tr><td>double</td> <td>avg(col), avg(DISTINCT col)</td> <td>求平均值</td></tr> <tr><td>double</td> <td>min(col)</td> <td>返回指定列中最小值</td></tr> <tr><td>double</td> <td>max(col)</td> <td>返回指定列中最大值</td></tr> <tr><td>double</td> <td>var_pop(col)</td> <td>返回指定列的方差</td></tr> <tr><td>double</td> <td>var_samp(col)</td> <td>返回指定列的样本方差</td></tr> <tr><td>double</td> <td>stddev_pop(col)</td> <td>返回指定列的偏差</td></tr> <tr><td>double</td> <td>stddev_samp(col)</td> <td>返回指定列的样本偏差</td></tr> <tr><td>double</td> <td>covar_pop(col1, col2)</td> <td>两列数值协方差</td></tr> <tr><td>double</td> <td>covar_samp(col1, col2)</td> <td>两列数值样本协方差</td></tr> <tr><td>double</td> <td>corr(col1, col2)</td> <td>返回两列数值的相关系数</td></tr> <tr><td>double</td> <td>percentile(col, p)</td> <td>返回数值区域的百分比数值点。0&lt;=P&lt;=1,否则返回NULL,不支持浮点型数值。</td></tr> <tr><td>array<double></double></td> <td>percentile(col, array(p~1,,\ [, p,,2,,]…))</td> <td>返回数值区域的一组百分比值分别对应的数值点。0&lt;=P&lt;=1,否则返回NULL,不支持浮点型数值。</td></tr> <tr><td>double</td> <td>percentile_approx(col, p[, B])</td> <td>Returns an approximate p^th^ percentile of a numeric column (including floating point types) in the group. The B parameter controls approximation accuracy at the cost of memory. Higher values yield better approximations, and the default is 10,000. When the number of distinct values in col is smaller than B, this gives an exact percentile value.</td></tr> <tr><td>array<double></double></td> <td>percentile_approx(col, array(p~1,, [, p,,2_]…) [, B])</td> <td>Same as above, but accepts and returns an array of percentile values instead of a single one.</td></tr> <tr><td>array&lt;struct{‘x’,'y’}&gt;</td> <td>histogram_numeric(col, b)</td> <td>Computes a histogram of a numeric column in the group using b non-uniformly spaced bins. The output is an array of size b of double-valued (x,y) coordinates that represent the bin centers and heights</td></tr> <tr><td>array</td> <td>collect_set(col)</td> <td>返回无重复记录</td></tr></tbody></table> <h3 id="内置表生成函数-udtf"><a href="#内置表生成函数-udtf" class="header-anchor">#</a> 内置表生成函数（UDTF）</h3> <table><thead><tr><th>返回类型</th> <th>函数</th> <th>说明</th></tr></thead> <tbody><tr><td>数组</td> <td>explode(array<TYPE> a)</TYPE></td> <td>数组一条记录中有多个参数，将参数拆分，每个参数生成一列。</td></tr> <tr><td></td> <td>json_tuple</td> <td>get_json_object 语句：<br>select a.timestamp, get_json_object(a.appevents, ‘$.eventid’), get_json_object(a.appenvets, ‘$.eventname’) from log a; <br>json_tuple语句: <br>select a.timestamp, b.* from log a lateral view json_tuple(a.appevent, ‘eventid’, ‘eventname’) b as f1, f2</td></tr></tbody></table> <h3 id="自定义函数"><a href="#自定义函数" class="header-anchor">#</a> 自定义函数</h3> <p><strong>自定义函数包括三种UDF、UDAF、UDTF</strong></p> <ol><li>UDF(User-Defined-Function) ：一进一出</li> <li>UDAF(User- Defined Aggregation Funcation) ：聚集函数，多进一出。Count/max/min</li> <li>UDTF(User-Defined Table-Generating Functions) :一进多出，如explore()</li></ol> <h4 id="udf-开发"><a href="#udf-开发" class="header-anchor">#</a> UDF 开发</h4> <ol><li>UDF函数可以直接应用于select语句，对查询结构做格式化处理后，再输出内容。</li> <li>编写UDF函数的时候需要注意一下几点：
<ul><li>自定义UDF需要继承org.apache.hadoop.hive.ql.UDF。</li> <li>需要实现evaluate函数，evaluate函数支持重载。</li></ul></li></ol> <h4 id="将jar包上传到虚拟机中"><a href="#将jar包上传到虚拟机中" class="header-anchor">#</a> 将jar包上传到虚拟机中</h4> <blockquote><p>注意：此种方式创建的函数属于临时函数，当关闭了当前会话之后，函数会无法使用，因为jar的引用没有了，无法找到对应的java文件进行处理，因此不推荐使用。</p></blockquote> <ol><li><p>把程序打包放到目标机器上去；</p></li> <li><p>进入hive客户端，添加jar包：add jar /run/jar/udf_test.jar;</p></li> <li><p>创建临时函数：CREATE TEMPORARY FUNCTION add_example AS 'hive.udf.Add';</p></li> <li><p>查询HQL语句：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">SELECT</span> add_example<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span> <span class="token keyword">FROM</span> scores<span class="token punctuation">;</span>
<span class="token keyword">SELECT</span> add_example<span class="token punctuation">(</span>scores<span class="token punctuation">.</span>math<span class="token punctuation">,</span> scores<span class="token punctuation">.</span>art<span class="token punctuation">)</span> <span class="token keyword">FROM</span> scores<span class="token punctuation">;</span>
<span class="token keyword">SELECT</span> add_example<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">6.8</span><span class="token punctuation">)</span> <span class="token keyword">FROM</span> scores<span class="token punctuation">;</span>
</code></pre></div></li> <li><p>销毁临时函数：DROP TEMPORARY FUNCTION add_example;</p></li></ol> <h4 id="将jar包上传到hdfs集群中"><a href="#将jar包上传到hdfs集群中" class="header-anchor">#</a> 将jar包上传到hdfs集群中</h4> <ol><li><p>把程序打包上传到hdfs的某个目录下</p></li> <li><p>创建函数：CREATE FUNCTION add_example AS 'hive.udf.Add' using jar &quot;hdfs://mycluster/jar/udf_test.jar&quot;;</p></li> <li><p>查询HQL语句：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">SELECT</span> add_example<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span> <span class="token keyword">FROM</span> scores<span class="token punctuation">;</span>
<span class="token keyword">SELECT</span> add_example<span class="token punctuation">(</span>scores<span class="token punctuation">.</span>math<span class="token punctuation">,</span> scores<span class="token punctuation">.</span>art<span class="token punctuation">)</span> <span class="token keyword">FROM</span> scores<span class="token punctuation">;</span>
<span class="token keyword">SELECT</span> add_example<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">6.8</span><span class="token punctuation">)</span> <span class="token keyword">FROM</span> scores<span class="token punctuation">;</span>
</code></pre></div></li> <li><p>销毁临时函数：DROP  FUNCTION add_example;</p></li></ol> <h3 id="hive使用sql计算word-count"><a href="#hive使用sql计算word-count" class="header-anchor">#</a> hive使用sql计算word count</h3> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">from</span> <span class="token punctuation">(</span><span class="token keyword">select</span> explode<span class="token punctuation">(</span>split<span class="token punctuation">(</span>要计算的列名<span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">)</span> word <span class="token keyword">from</span> 表名<span class="token punctuation">)</span> t
<span class="token keyword">insert</span> <span class="token keyword">into</span> 结果表名 <span class="token keyword">select</span> word<span class="token punctuation">,</span> <span class="token function">count</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span> <span class="token keyword">group</span> <span class="token keyword">by</span> t<span class="token punctuation">.</span>word
</code></pre></div><h3 id="hive-sql解析工具"><a href="#hive-sql解析工具" class="header-anchor">#</a> hive - sql解析工具</h3> <div class="language- extra-class"><pre class="language-text"><code>calcite
</code></pre></div><blockquote><p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fcalcite.apache.org%2F" target="_blank" rel="noopener noreferrer">Apache Calcite<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 是一款开源SQL解析工具, 可以将各种SQL语句解析成抽象语法术AST(Abstract Syntax Tree), 之后通过操作AST就可以把SQL中所要表达的算法与关系体现在具体代码之中。</p></blockquote> <h2 id="hive参数操作"><a href="#hive参数操作" class="header-anchor">#</a> Hive参数操作</h2> <h3 id="hive参数介绍"><a href="#hive参数介绍" class="header-anchor">#</a> hive参数介绍</h3> <p>hive当中的参数、变量都是以命名空间开头的，详情如下表所示：</p> <table><thead><tr><th><strong>命名空间</strong></th> <th><strong>读写权限</strong></th> <th><strong>含义</strong></th></tr></thead> <tbody><tr><td>hiveconf</td> <td>可读写</td> <td>hive-site.xml当中的各配置变量例：hive --hiveconf hive.cli.print.header=true</td></tr> <tr><td>system</td> <td>可读写</td> <td>系统变量，包含JVM运行参数等例：system:user.name=root</td></tr> <tr><td>env</td> <td>只读</td> <td>环境变量例：env：JAVA_HOME</td></tr> <tr><td>hivevar</td> <td>可读写</td> <td>例：hive -d val=key</td></tr></tbody></table> <p>hive的变量可以通过${}方式进行引用，其中system、env下的变量必须以前缀开头</p> <h3 id="hive参数的设置方式"><a href="#hive参数的设置方式" class="header-anchor">#</a> hive参数的设置方式</h3> <ol><li><p>在${HIVE_HOME}/conf/hive-site.xml文件中添加参数设置</p> <p><strong>注意：永久生效，所有的hive会话都会加载对应的配置</strong></p></li> <li><p>在启动hive cli时，通过--hiveconf key=value的方式进行设置</p> <p>例如：hive --hiveconf hive.cli.print.header=true</p> <p><strong>注意：只在当前会话有效，退出会话之后参数失效</strong></p></li> <li><p>在进入到cli之后，通过set命令设置</p> <p>例如：set hive.cli.print.header=true;</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 在hive cli控制台可以通过set对hive中的参数进行查询设置</span>
<span class="token comment">-- set设置</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>cli<span class="token punctuation">.</span><span class="token keyword">print</span><span class="token punctuation">.</span>header<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token comment">-- set查看</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>cli<span class="token punctuation">.</span><span class="token keyword">print</span><span class="token punctuation">.</span>header
<span class="token comment">-- set查看全部属性</span>
<span class="token keyword">set</span>
</code></pre></div><p><strong>注意：只在当前会话有效，退出会话之后参数失效</strong></p></li> <li><p>hive参数初始化设置</p> <p>在当前用户的家目录下创建**.hiverc**文件，在当前文件中设置hive参数的命令，每次进入hive cli的时候，都会加载.hiverc的文件，执行文件中的命令。</p> <p><strong>注意：在当前用户的家目录下还会存在.hivehistory文件，此文件中保存了hive cli中执行的所有命令</strong></p></li></ol> <h2 id="hive运行方式"><a href="#hive运行方式" class="header-anchor">#</a> Hive运行方式</h2> <h3 id="命令行方式或者控制台模式"><a href="#命令行方式或者控制台模式" class="header-anchor">#</a> 命令行方式或者控制台模式</h3> <ol><li><p>在命令行中可以直接输入SQL语句，例如：select * from table_name</p></li> <li><p>在命令行中可以与HDFS交互，例如：dfs ls /</p></li> <li><p>在命令行中可以与linux交互，例如：! pwd或者! ls /</p> <p><strong>注意：与linux交互的时候必须要加!</strong></p></li></ol> <h3 id="脚本运行方式-实际生产环境中用最多"><a href="#脚本运行方式-实际生产环境中用最多" class="header-anchor">#</a> 脚本运行方式（实际生产环境中用最多）</h3> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- hive直接执行sql命令，可以写一个sql语句，也可以使用;分割写多个sql语句</span>
hive <span class="token operator">-</span>e <span class="token string">&quot;&quot;</span>
<span class="token comment">-- hive执行sql命令，将sql语句执行的结果重定向到某一个文件中</span>
hive <span class="token operator">-</span>e <span class="token string">&quot;&quot;</span><span class="token operator">&gt;</span>aaa
<span class="token comment">-- hive静默输出模式(-S)，输出的结果中不包含ok，time token等关键字</span>
hive <span class="token operator">-</span>S <span class="token operator">-</span>e <span class="token string">&quot;&quot;</span><span class="token operator">&gt;</span>aaa
<span class="token comment">-- hive可以直接读取文件中的sql命令，进行执行</span>
hive <span class="token operator">-</span>f <span class="token keyword">file</span>
<span class="token comment">-- hive可以从文件中读取命令，并且执行初始化操作</span>
hive <span class="token operator">-</span>i <span class="token operator">/</span>home<span class="token operator">/</span>my<span class="token operator">/</span>hive<span class="token operator">-</span>init<span class="token punctuation">.</span><span class="token keyword">sql</span>
<span class="token comment">-- 在hive的命令行中也可以执行外部文件中的命令</span>
source <span class="token keyword">file</span> <span class="token punctuation">(</span>在hive cli中运行<span class="token punctuation">)</span>
</code></pre></div><h3 id="jdbc方式-hiveserver2"><a href="#jdbc方式-hiveserver2" class="header-anchor">#</a> JDBC方式：hiveserver2</h3> <p>程序开发通过jdbc方式进行访问。</p> <h3 id="web-gui接口-hwi、hue等"><a href="#web-gui接口-hwi、hue等" class="header-anchor">#</a> web GUI接口（hwi、hue等）</h3> <p>hwi在2.2版本以后，已经删除了，</p> <h4 id="搭建hue"><a href="#搭建hue" class="header-anchor">#</a> 搭建Hue</h4> <h2 id="hive视图"><a href="#hive视图" class="header-anchor">#</a> Hive视图</h2> <h3 id="hive-lateral-view"><a href="#hive-lateral-view" class="header-anchor">#</a> Hive Lateral View</h3> <blockquote><ol><li>Lateral View用于和UDTF函数（explode、split）结合来使用。</li> <li>首先通过UDTF函数拆分成多行，再将多行结果组合成一个支持别名的虚拟表。</li> <li>主要解决在select使用UDTF做查询过程中，查询只能包含单个UDTF，不能包含其他字段、以及多个UDTF的问题。</li></ol></blockquote> <h4 id="语法"><a href="#语法" class="header-anchor">#</a> 语法</h4> <div class="language-sql extra-class"><pre class="language-sql"><code>LATERAL <span class="token keyword">VIEW</span> udtf<span class="token punctuation">(</span>expression<span class="token punctuation">)</span> tableAlias <span class="token keyword">AS</span> columnAlias <span class="token punctuation">(</span><span class="token string">','</span> columnAlias<span class="token punctuation">)</span>
</code></pre></div><h4 id="案例-2"><a href="#案例-2" class="header-anchor">#</a> 案例</h4> <p>统计人员表中共有多少种爱好、多少个城市?</p> <p><img src="/images/Hive-Lateral-View%E6%A1%88%E4%BE%8B.png" alt="Hive-Lateral-View案例"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span><span class="token punctuation">(</span>myCol1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span><span class="token punctuation">(</span>myCol2<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">from</span> psn2 
LATERAL <span class="token keyword">VIEW</span> explode<span class="token punctuation">(</span>likes<span class="token punctuation">)</span> myTable1 <span class="token keyword">AS</span> myCol1 
LATERAL <span class="token keyword">VIEW</span> explode<span class="token punctuation">(</span>address<span class="token punctuation">)</span> myTable2 <span class="token keyword">AS</span> myCol2<span class="token punctuation">,</span> myCol3<span class="token punctuation">;</span>
</code></pre></div><h3 id="hive普通视图"><a href="#hive普通视图" class="header-anchor">#</a> Hive普通视图</h3> <blockquote><p>Hive 中的视图和RDBMS中视图的概念一致，都是一组数据的逻辑表示，本质上就是一条SELECT语句的结果集。视图是纯粹的逻辑对象，没有关联的存储(Hive 3.0.0引入的物化视图除外)，当查询引用视图时，Hive可以将视图的定义与查询结合起来，例如将查询中的过滤器推送到视图中。</p></blockquote> <h4 id="hive视图特点"><a href="#hive视图特点" class="header-anchor">#</a> Hive视图特点</h4> <ol><li>不支持物化视图</li> <li>只能查询，不能做加载数据操作</li> <li>视图的创建，只是保存一份元数据，查询视图时才执行对应的子查询</li> <li>view定义中若包含了ORDER BY/LIMIT语句，当查询视图时也进行ORDER BY/LIMIT语句操作，view当中			  定义的优先级更高</li> <li>view支持迭代视图</li></ol> <h4 id="hive视图语法"><a href="#hive视图语法" class="header-anchor">#</a> Hive视图语法</h4> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 创建视图：</span>
<span class="token keyword">CREATE</span> <span class="token keyword">VIEW</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token operator">NOT</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>db_name<span class="token punctuation">.</span><span class="token punctuation">]</span>view_name 
  <span class="token punctuation">[</span><span class="token punctuation">(</span>column_name <span class="token punctuation">[</span><span class="token keyword">COMMENT</span> column_comment<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token punctuation">]</span>
  <span class="token punctuation">[</span><span class="token keyword">COMMENT</span> view_comment<span class="token punctuation">]</span>
  <span class="token punctuation">[</span>TBLPROPERTIES <span class="token punctuation">(</span>property_name <span class="token operator">=</span> property_value<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
  <span class="token keyword">AS</span> <span class="token keyword">SELECT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">;</span>
<span class="token comment">-- 查询视图：</span>
<span class="token keyword">select</span> colums <span class="token keyword">from</span> <span class="token keyword">view</span><span class="token punctuation">;</span>
<span class="token comment">-- 删除视图：</span>
<span class="token keyword">DROP</span> <span class="token keyword">VIEW</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>db_name<span class="token punctuation">.</span><span class="token punctuation">]</span>view_name<span class="token punctuation">;</span>
</code></pre></div><h2 id="hive索引"><a href="#hive索引" class="header-anchor">#</a> Hive索引</h2> <blockquote><p>为了提高数据的检索效率，可以使用hive的索引</p></blockquote> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">--创建索引：</span>
<span class="token keyword">create</span> <span class="token keyword">index</span> t1_index <span class="token keyword">on</span> <span class="token keyword">table</span> psn2<span class="token punctuation">(</span>name<span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token string">'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler'</span> <span class="token keyword">with</span> deferred rebuild <span class="token operator">in</span> <span class="token keyword">table</span>    t1_index_table<span class="token punctuation">;</span>
<span class="token comment">--as：指定索引器；</span>
<span class="token comment">--in table：指定索引表，若不指定默认生成在default__psn2_t1_index__表中</span>
<span class="token keyword">create</span> <span class="token keyword">index</span> t1_index <span class="token keyword">on</span> <span class="token keyword">table</span> psn2<span class="token punctuation">(</span>name<span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token string">'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler'</span> <span class="token keyword">with</span> deferred rebuild<span class="token punctuation">;</span>
<span class="token comment">--查询索引</span>
<span class="token keyword">show</span> <span class="token keyword">index</span> <span class="token keyword">on</span> psn2<span class="token punctuation">;</span>
<span class="token comment">--重建索引（建立索引之后必须重建索引才能生效）</span>
<span class="token keyword">ALTER</span> <span class="token keyword">INDEX</span> t1_index <span class="token keyword">ON</span> psn2 REBUILD<span class="token punctuation">;</span>
<span class="token comment">--删除索引</span>
<span class="token keyword">DROP</span> <span class="token keyword">INDEX</span> <span class="token keyword">IF</span> <span class="token keyword">EXISTS</span> t1_index <span class="token keyword">ON</span> psn2<span class="token punctuation">;</span>
</code></pre></div><h2 id="hive权限管理"><a href="#hive权限管理" class="header-anchor">#</a> Hive权限管理</h2> <h3 id="hive授权模型介绍"><a href="#hive授权模型介绍" class="header-anchor">#</a> hive授权模型介绍</h3> <ol><li><p>Storage Based Authorization in the Metastore Server</p> <p>基于存储的授权 - 可以对Metastore中的元数据进行保护，但是没有提供更加细粒度的访问控制（例如：列级别、行级别）</p></li> <li><p>SQL Standards Based Authorization in HiveServer2</p> <p>基于SQL标准的Hive授权 - 完全兼容SQL的授权模型，推荐使用该模式。</p></li> <li><p>Default Hive Authorization (Legacy Mode)</p> <p>hive默认授权 - 设计目的仅仅只是为了防止用户产生误操作，而不是防止恶意用户访问未经授权的数据。</p></li></ol> <h3 id="基于sql标准的hive授权"><a href="#基于sql标准的hive授权" class="header-anchor">#</a> 基于SQL标准的Hive授权</h3> <ol><li>完全兼容SQL的授权模型</li> <li>除支持对于用户的授权认证，还支持角色role的授权认证
<ul><li>role可理解为是一组权限的集合，通过role为用户授权</li> <li>一个用户可以具有一个或多个角色</li> <li>默认包含另种角色：public、admin</li></ul></li></ol> <p><strong>限制：</strong></p> <ol><li><p>启用当前认证方式之后，dfs, add, delete, compile, and reset等命令被禁用。</p></li> <li><p>通过set命令设置hive configuration的方式被限制某些用户使用。</p> <p>(可通过修改配置文件hive-site.xml中hive.security.authorization.sqlstd.confwhitelist进行配置)</p></li> <li><p>添加、删除函数以及宏的操作，仅为具有admin的用户开放。</p></li> <li><p>用户自定义函数（开放支持永久的自定义函数），可通过具有admin角色的用户创建，其他用户都可以使用。</p></li> <li><p>Transform功能被禁用。</p></li></ol> <h3 id="hive权限配置"><a href="#hive权限配置" class="header-anchor">#</a> Hive权限配置</h3> <p>cd $HIVE_HOME/conf</p> <p>vim hive-site.xml</p> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.security.authorization.enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.server2.enable.doAs<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.users.in.admin.role<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>root<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.security.authorization.manager<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.security.authenticator.manager<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop.hive.ql.security.SessionStateUserAuthenticator<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><h3 id="hive权限管理命令"><a href="#hive权限管理命令" class="header-anchor">#</a> Hive权限管理命令</h3> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 角色的添加、删除、查看、设置：</span>
<span class="token comment">-- 创建角色</span>
<span class="token keyword">create</span> role role_name<span class="token punctuation">;</span>  
<span class="token comment">-- 删除角色</span>
<span class="token keyword">drop</span> role role_name<span class="token punctuation">;</span> 
<span class="token comment">-- 设置角色</span>
<span class="token keyword">set</span> role <span class="token punctuation">(</span>role_name<span class="token operator">|</span><span class="token keyword">all</span><span class="token operator">|</span>none<span class="token punctuation">)</span><span class="token punctuation">;</span> 
<span class="token comment">-- 查看当前具有的角色</span>
<span class="token keyword">show</span> <span class="token keyword">current</span> roles<span class="token punctuation">;</span>
<span class="token comment">-- 查看所有存在的角色  </span>
<span class="token keyword">show</span> roles<span class="token punctuation">;</span>
<span class="token comment">-- 把admin角色授权给test用户</span>
<span class="token comment">-- show 角色名 to (role rolename|user username) with admin option;</span>
<span class="token comment">-- with admin option;让其他角色也有admin的能力</span>
<span class="token keyword">show</span> admin <span class="token keyword">to</span> role test <span class="token keyword">with</span> admin <span class="token keyword">option</span><span class="token punctuation">;</span>
<span class="token comment">-- 查看角色的授权</span>
<span class="token comment">-- show role grant (user|role) 角色名称;</span>
<span class="token keyword">show</span> role <span class="token keyword">grant</span> role test<span class="token punctuation">;</span>
<span class="token comment">-- 权限回收</span>
<span class="token comment">-- 把admin角色从test角色中收回来</span>
<span class="token keyword">revoke</span> admin <span class="token keyword">from</span> role test<span class="token punctuation">;</span>
</code></pre></div><h3 id="hive权限分配图"><a href="#hive权限分配图" class="header-anchor">#</a> Hive权限分配图</h3> <table><thead><tr><th>Action</th> <th>Select</th> <th>Insert</th> <th>Update</th> <th>Delete</th> <th>Owership</th> <th>Admin</th> <th>URL Privilege(RWX Permission + Ownership)</th></tr></thead> <tbody><tr><td>ALTER DATABASE</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td></tr> <tr><td>ALTER INDEX PROPERTIES</td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td></td></tr> <tr><td>ALTER INDEX REBUILD</td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td></td></tr> <tr><td>ALTER PARTITION LOCATION</td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td>Y (for new partition location)</td></tr> <tr><td>ALTER TABLE (all of them except the ones above)</td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td></td></tr> <tr><td>ALTER TABLE ADD PARTITION</td> <td></td> <td>Y</td> <td></td> <td></td> <td></td> <td></td> <td>Y (for partition location)</td></tr> <tr><td>ALTER TABLE DROP PARTITION</td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td></td> <td></td></tr> <tr><td>ALTER TABLE LOCATION</td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td>Y (for new location)</td></tr> <tr><td>ALTER VIEW PROPERTIES</td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td></td></tr> <tr><td>ALTER VIEW RENAME</td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td></td></tr> <tr><td>ANALYZE TABLE</td> <td>Y</td> <td>Y</td> <td></td> <td></td> <td></td> <td></td> <td></td></tr> <tr><td>CREATE DATABASE</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td>Y (if custom location specified)</td></tr> <tr><td>CREATE FUNCTION</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td></tr> <tr><td>CREATE INDEX</td> <td></td> <td></td> <td></td> <td></td> <td>Y (of table)</td> <td></td> <td></td></tr> <tr><td>CREATE MACRO</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td></tr> <tr><td>CREATE TABLE</td> <td></td> <td></td> <td></td> <td></td> <td>Y (of database)</td> <td></td> <td>Y  (for create external table – the location)</td></tr> <tr><td>CREATE TABLE AS SELECT</td> <td>Y (of input)</td> <td></td> <td></td> <td></td> <td>Y (of database)</td> <td></td> <td></td></tr> <tr><td>CREATE VIEW</td> <td>Y + G</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr> <tr><td>DELETE</td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td></td> <td></td></tr> <tr><td>DESCRIBE TABLE</td> <td>Y</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr> <tr><td>DROP DATABASE</td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td></td></tr> <tr><td>DROP FUNCTION</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td></tr> <tr><td>DROP INDEX</td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td></td></tr> <tr><td>DROP MACRO</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td></tr> <tr><td>DROP TABLE</td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td></td></tr> <tr><td>DROP VIEW</td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td></td></tr> <tr><td>DROP VIEW PROPERTIES</td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td></td></tr> <tr><td>EXPLAIN</td> <td>Y</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr> <tr><td>INSERT</td> <td></td> <td>Y</td> <td></td> <td>Y (for OVERWRITE)</td> <td></td> <td></td> <td></td></tr> <tr><td>LOAD</td> <td></td> <td>Y (output)</td> <td></td> <td>Y (output)</td> <td></td> <td></td> <td>Y (input location)</td></tr> <tr><td>MSCK (metastore check)</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td></tr> <tr><td>SELECT</td> <td>Y</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr> <tr><td>SHOW COLUMNS</td> <td>Y</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr> <tr><td>SHOW CREATE TABLE</td> <td>Y+G</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr> <tr><td>SHOW PARTITIONS</td> <td>Y</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr> <tr><td>SHOW TABLE PROPERTIES</td> <td>Y</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr> <tr><td>SHOW TABLE STATUS</td> <td>Y</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr> <tr><td>TRUNCATE TABLE</td> <td></td> <td></td> <td></td> <td></td> <td>Y</td> <td></td> <td></td></tr> <tr><td>UPDATE</td> <td></td> <td></td> <td>Y</td> <td></td> <td></td> <td></td> <td></td></tr></tbody></table> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 给用户赋权</span>
<span class="token comment">-- grant select on 表名 to user 用户名 with grant option;</span>
<span class="token comment">-- with grant option;让其他用户也有授权的能力</span>
<span class="token keyword">grant</span> <span class="token keyword">select</span> <span class="token keyword">on</span> psn <span class="token keyword">to</span> <span class="token keyword">user</span> abcd <span class="token keyword">with</span> <span class="token keyword">grant</span> <span class="token keyword">option</span><span class="token punctuation">;</span>
<span class="token comment">-- 查看用户有哪些权限</span>
<span class="token comment">-- show grant user 用户名 on 表名;</span>
<span class="token keyword">show</span> <span class="token keyword">grant</span> <span class="token keyword">user</span> abds <span class="token keyword">on</span> psm<span class="token punctuation">;</span>
<span class="token comment">--回收权限</span>
<span class="token comment">-- revoke update on 表名 from user 用户名;</span>
<span class="token keyword">revoke</span> <span class="token keyword">update</span> <span class="token keyword">on</span> psn <span class="token keyword">from</span> <span class="token keyword">user</span> abdc<span class="token punctuation">;</span>
</code></pre></div><h2 id="hive优化"><a href="#hive优化" class="header-anchor">#</a> Hive优化</h2> <blockquote><p>Hive的存储层依托于HDFS，Hive的计算层依托于MapReduce，一般Hive的执行效率主要取决于SQL语句的执行效率，因此，Hive的优化的核心思想是MapReduce的优化。</p> <p>hive的sql转mr任务经历的5个步骤：</p> <ol><li>抽象语法树</li> <li>查新块</li> <li>逻辑查询计划</li> <li>物理查询计划</li> <li>优化执行</li></ol></blockquote> <h3 id="查看hive执行计划-小白慎用"><a href="#查看hive执行计划-小白慎用" class="header-anchor">#</a> 查看Hive执行计划（小白慎用）</h3> <blockquote><p>Hive的SQL语句在执行之前需要将SQL语句转换成MapReduce任务，因此需要了解具体的转换过程，可以在SQL语句中输入如下命令查看具体的执行计划。</p></blockquote> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 查看执行计划，添加extended关键字可以查看更加详细的执行计划</span>
<span class="token keyword">explain</span> <span class="token punctuation">[</span><span class="token keyword">extended</span><span class="token punctuation">]</span> query
</code></pre></div><h3 id="hive的抓取策略"><a href="#hive的抓取策略" class="header-anchor">#</a> Hive的抓取策略</h3> <blockquote><p>Hive的某些SQL语句需要转换成MapReduce的操作，某些SQL语句就不需要转换成MapReduce操作，但是同学们需要注意，理论上来说，所有的SQL语句都需要转换成MapReduce操作，只不过Hive在转换SQL语句的过程中会做部分优化，使某些简单的操作不再需要转换成MapReduce，例如：</p> <ol><li>select 仅支持本表字段</li> <li>where仅对本表字段做条件过滤</li></ol></blockquote> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 查看Hive的数据抓取策略（优化部分情况不用转换mr任务）</span>
<span class="token keyword">Set</span> hive<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span>task<span class="token punctuation">.</span>conversion<span class="token operator">=</span>none<span class="token operator">/</span>more<span class="token punctuation">;</span>
</code></pre></div><h3 id="hive本地模式"><a href="#hive本地模式" class="header-anchor">#</a> Hive本地模式</h3> <blockquote><p>类似于MapReduce的操作，Hive的运行也分为本地模式和集群模式，在开发阶段可以选择使用本地执行，提高SQL语句的执行效率，验证SQL语句是否正确。</p></blockquote> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 设置本地模式</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token punctuation">.</span><span class="token keyword">local</span><span class="token punctuation">.</span>auto<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre></div><p><strong>需要注意的是：</strong></p> <blockquote><p>要想使用Hive的本地模式，加载数据文件大小不能超过128M，或者文件个数不能超过4个，如果超过128M或者文件个数超过了4个，就算设置了本地模式，也会按照集群模式运行。</p></blockquote> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 设置读取数据量的大小限制</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token punctuation">.</span><span class="token keyword">local</span><span class="token punctuation">.</span>auto<span class="token punctuation">.</span>inputbytes<span class="token punctuation">.</span>max<span class="token operator">=</span><span class="token number">128</span>M
</code></pre></div><h3 id="hive并行模式"><a href="#hive并行模式" class="header-anchor">#</a> Hive并行模式</h3> <blockquote><p>在SQL语句足够复杂的情况下，可能在一个SQL语句中包含多个子查询语句，且多个子查询语句之间没有任何依赖关系，此时，可以Hive运行的并行度</p></blockquote> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 设置Hive SQL的并行度</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>parallel<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre></div><p><strong>需要注意的是：</strong></p> <blockquote><p>Hive的并行度并不是无限增加的，在一次SQL计算中，可以通过以下参数来设置并行的job的个数</p></blockquote> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 设置一次SQL计算允许并行执行的job个数的最大值，默认值8</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>parallel<span class="token punctuation">.</span>thread<span class="token punctuation">.</span>number
</code></pre></div><h3 id="hive严格模式"><a href="#hive严格模式" class="header-anchor">#</a> Hive严格模式</h3> <blockquote><p>Hive中为了提高SQL语句的执行效率，可以设置严格模式，充分利用Hive的某些特点。</p></blockquote> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 设置Hive的严格模式</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>mapred<span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token operator">=</span>strict<span class="token punctuation">;</span>
</code></pre></div><p><strong>需要注意的是：</strong></p> <p>当设置严格模式之后，对于查询会有如下限制：</p> <ol><li>对于分区表，必须添加where对于分区字段的条件过滤</li> <li>order by语句必须包含limit输出限制</li> <li>限制执行笛卡尔积的查询</li></ol> <h3 id="hive排序"><a href="#hive排序" class="header-anchor">#</a> Hive排序</h3> <blockquote><p>在编写SQL语句的过程中，很多情况下需要对数据进行排序操作，Hive中支持多种排序操作适合不同的应用场景。</p></blockquote> <ol><li><p>Order By - 对于查询结果做全排序，只允许有一个reduce处理</p> <p><strong>（当数据量较大时，应慎用。严格模式下，必须结合limit来使用）</strong></p></li> <li><p>Sort By - 对于单个reduce的数据进行排序</p></li> <li><p>Distribute By - 分区排序，经常和Sort By结合使用</p></li> <li><p>Cluster By - 相当于 Sort By + Distribute By</p> <p><strong>Cluster By不能通过asc、desc的方式指定排序规则；可通过 distribute by column sort by column asc|desc 的方式</strong></p></li></ol> <h3 id="hive-join"><a href="#hive-join" class="header-anchor">#</a> Hive join</h3> <blockquote><p>Hive 在多个表的join操作时尽可能多的使用相同的连接键，这样在转换MR任务时会转换成少的MR的任务。</p></blockquote> <h4 id="手动map-join-在map端完成join操作"><a href="#手动map-join-在map端完成join操作" class="header-anchor">#</a> 手动Map join:在map端完成join操作</h4> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- SQL方式，在SQL语句中添加MapJoin标记（mapjoin hint）</span>
<span class="token keyword">SELECT</span>  <span class="token comment">/*+ MAPJOIN(smallTable) */</span>  smallTable<span class="token punctuation">.</span><span class="token keyword">key</span><span class="token punctuation">,</span>  bigTable<span class="token punctuation">.</span><span class="token keyword">value</span> 
<span class="token keyword">FROM</span>  smallTable  <span class="token keyword">JOIN</span>  bigTable  <span class="token keyword">ON</span>  smallTable<span class="token punctuation">.</span><span class="token keyword">key</span>  <span class="token operator">=</span>  bigTable<span class="token punctuation">.</span><span class="token keyword">key</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="开启自动的map-join"><a href="#开启自动的map-join" class="header-anchor">#</a> 开启自动的Map Join</h4> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 通过修改以下配置启用自动的mapjoin：</span>
<span class="token comment">-- 该参数为true时，Hive自动对左边的表统计量，如果是小表就加入内存，即对小表使用Map join（放入内存中）</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>auto<span class="token punctuation">.</span><span class="token keyword">convert</span><span class="token punctuation">.</span><span class="token keyword">join</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token comment">-- 大表小表判断的阈值，如果表的大小小于该值则会被加载到内存中运行，默认25000000，如果调大会占用map端很大内存</span>
hive<span class="token punctuation">.</span>mapjoin<span class="token punctuation">.</span>smalltable<span class="token punctuation">.</span>filesize <span class="token operator">=</span> <span class="token number">25000000</span><span class="token punctuation">;</span>
<span class="token comment">--（默认值：true，如果手动自动都有，自动优先；如果为false，手动优先）</span>
hive<span class="token punctuation">.</span><span class="token keyword">ignore</span><span class="token punctuation">.</span>mapjoin<span class="token punctuation">.</span>hint <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="大表join大表"><a href="#大表join大表" class="header-anchor">#</a> 大表join大表</h4> <ol><li>空key过滤：有时join超时是因为某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，我们需要在SQL语句中进行过滤。</li> <li>空key转换：有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以表a中key为空的字段赋一个随机的值，使得数据随机均匀地分不到不同的reducer上</li></ol> <h3 id="map-side聚合"><a href="#map-side聚合" class="header-anchor">#</a> Map-Side聚合</h3> <blockquote><p>Hive的某些SQL操作可以实现map端的聚合，类似于MR的combine操作</p></blockquote> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 通过设置以下参数开启在Map端的聚合：</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>map<span class="token punctuation">.</span>aggr<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token comment">-- 相关配置参数：</span>
<span class="token comment">-- map端group by执行聚合时处理的多少行数据（默认：100000）</span>
hive<span class="token punctuation">.</span>groupby<span class="token punctuation">.</span>mapaggr<span class="token punctuation">.</span>checkinterval： 
<span class="token comment">-- 进行聚合的最小比例（预先对100000条数据做聚合，若聚合之后的数据量/100000的值大于该配置0.5，则不会聚合）</span>
hive<span class="token punctuation">.</span>map<span class="token punctuation">.</span>aggr<span class="token punctuation">.</span><span class="token keyword">hash</span><span class="token punctuation">.</span>min<span class="token punctuation">.</span>reduction： 
<span class="token comment">--m ap端聚合使用的内存的最大值</span>
hive<span class="token punctuation">.</span>map<span class="token punctuation">.</span>aggr<span class="token punctuation">.</span><span class="token keyword">hash</span><span class="token punctuation">.</span>percentmemory： 
<span class="token comment">-- 是否对GroupBy产生的数据倾斜做优化，默认为false</span>
hive<span class="token punctuation">.</span>groupby<span class="token punctuation">.</span>skewindata
</code></pre></div><h3 id="合并小文件"><a href="#合并小文件" class="header-anchor">#</a> 合并小文件</h3> <blockquote><p>Hive在操作的时候，如果文件数目小，容易在文件存储端造成压力，给hdfs造成压力，影响效率</p></blockquote> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 设置合并属性</span>
<span class="token comment">-- 是否合并map输出文件：</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>mapfiles<span class="token operator">=</span><span class="token boolean">true</span>
<span class="token comment">-- 是否合并reduce输出文件：</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>mapredfiles<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token comment">-- 合并文件的大小：</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>size<span class="token punctuation">.</span>per<span class="token punctuation">.</span>task<span class="token operator">=</span><span class="token number">256</span><span class="token operator">*</span><span class="token number">1000</span><span class="token operator">*</span><span class="token number">1000</span>
</code></pre></div><h3 id="合理设置map以及reduce的数量"><a href="#合理设置map以及reduce的数量" class="header-anchor">#</a> 合理设置Map以及Reduce的数量</h3> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- Map数量相关的参数</span>
<span class="token comment">-- 一个split的最大值，即每个map处理文件的最大值</span>
<span class="token keyword">set</span> mapred<span class="token punctuation">.</span>max<span class="token punctuation">.</span>split<span class="token punctuation">.</span>size
<span class="token comment">-- 一个节点上split的最小值</span>
<span class="token keyword">set</span> mapred<span class="token punctuation">.</span>min<span class="token punctuation">.</span>split<span class="token punctuation">.</span>size<span class="token punctuation">.</span>per<span class="token punctuation">.</span>node
<span class="token comment">-- 一个机架上split的最小值</span>
<span class="token keyword">set</span> mapred<span class="token punctuation">.</span>min<span class="token punctuation">.</span>split<span class="token punctuation">.</span>size<span class="token punctuation">.</span>per<span class="token punctuation">.</span>rack
<span class="token comment">-- Reduce数量相关的参数</span>
<span class="token comment">-- 强制指定reduce任务的数量</span>
<span class="token keyword">set</span> mapred<span class="token punctuation">.</span>reduce<span class="token punctuation">.</span>tasks
<span class="token comment">-- 每个reduce任务处理的数据量</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>reducers<span class="token punctuation">.</span>bytes<span class="token punctuation">.</span>per<span class="token punctuation">.</span>reducer
<span class="token comment">-- 每个任务最大的reduce数</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>reducers<span class="token punctuation">.</span>max
</code></pre></div><h3 id="jvm重用"><a href="#jvm重用" class="header-anchor">#</a> JVM重用</h3> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">/*
适用场景：
	1、小文件个数过多
	2、task个数过多
缺点：
	设置开启之后，task插槽会一直占用资源，不论是否有task运行，直到所有的task即整个job全部执行完成时，才会释放所有的task插槽资源！
*/</span>
<span class="token keyword">set</span> mapred<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reuse<span class="token punctuation">.</span>jvm<span class="token punctuation">.</span>num<span class="token punctuation">.</span>tasks<span class="token operator">=</span>n<span class="token punctuation">;</span><span class="token comment">--（n为task插槽个数）</span>
</code></pre></div><h2 id="hadoop压缩配置"><a href="#hadoop压缩配置" class="header-anchor">#</a> Hadoop压缩配置</h2> <h3 id="mr支持的压缩编码"><a href="#mr支持的压缩编码" class="header-anchor">#</a> MR支持的压缩编码</h3> <table><thead><tr><th>压缩格式</th> <th>工具</th> <th>算法</th> <th>文件扩展名</th> <th>是否可切分</th></tr></thead> <tbody><tr><td>DEFAULT</td> <td>无</td> <td>DEFAULT</td> <td>.deflate</td> <td>否</td></tr> <tr><td>Gzip</td> <td>gzip</td> <td>DEFAULT</td> <td>.gz</td> <td>否</td></tr> <tr><td>bzip2</td> <td>bzip2</td> <td>bzip2</td> <td>.bz2</td> <td>是</td></tr> <tr><td>LZO</td> <td>lzop</td> <td>LZO</td> <td>.lzo</td> <td>否</td></tr> <tr><td>LZ4</td> <td>无</td> <td>LZ4</td> <td>.lz4</td> <td>否</td></tr> <tr><td>Snappy</td> <td>无</td> <td>Snappy</td> <td>.snappy</td> <td>否</td></tr></tbody></table> <p><strong>为了支持多种压缩/解压缩算法，Hadoop引入了编码/解码器，如下表所示：</strong></p> <table><thead><tr><th>压缩格式</th> <th>对应的编码/解码器</th></tr></thead> <tbody><tr><td>DEFLATE</td> <td>org.apache.hadoop.io.compress.DefaultCodec</td></tr> <tr><td>gzip</td> <td>org.apache.hadoop.io.compress.GzipCodec</td></tr> <tr><td>bzip2</td> <td>org.apache.hadoop.io.compress.BZip2Codec</td></tr> <tr><td>LZO</td> <td>com.hadoop.compression.lzo.LzopCodec</td></tr> <tr><td>LZ4</td> <td>org.apache.hadoop.io.compress.Lz4Codec</td></tr> <tr><td>Snappy</td> <td>org.apache.hadoop.io.compress.SnappyCodec</td></tr></tbody></table> <h3 id="压缩配置参数"><a href="#压缩配置参数" class="header-anchor">#</a> 压缩配置参数</h3> <blockquote><p>要在Hadoop中启用压缩，可以配置如下参数（mapred-site.xml文件中）：</p></blockquote> <table><thead><tr><th>参数</th> <th>默认值</th> <th>阶段</th> <th>建议</th></tr></thead> <tbody><tr><td>io.compression.codecs   <br>(在core-site.xml中配置)</td> <td>org.apache.hadoop.io.compress.DefaultCodec, <br>org.apache.hadoop.io.compress.GzipCodec, <br>org.apache.hadoop.io.compress.BZip2Codec,<br>org.apache.hadoop.io.compress.Lz4Codec</td> <td>输入压缩</td> <td>Hadoop使用文件扩展名判断是否支持某种编解码器</td></tr> <tr><td>mapreduce.map.output.compress</td> <td>false</td> <td>mapper输出</td> <td>这个参数设为true启用压缩</td></tr> <tr><td>mapreduce.map.output.compress.codec</td> <td>org.apache.hadoop.io.compress.DefaultCodec</td> <td>mapper输出</td> <td>使用LZO、LZ4或snappy编解码器在此阶段压缩数据</td></tr> <tr><td>mapreduce.output.fileoutputformat.compress</td> <td>false</td> <td>reducer输出</td> <td>这个参数设为true启用压缩</td></tr> <tr><td>mapreduce.output.fileoutputformat.compress.codec</td> <td>org.apache.hadoop.io.compress. DefaultCodec</td> <td>reducer输出</td> <td>使用标准工具或者编解码器，如gzip和bzip2</td></tr> <tr><td>mapreduce.output.fileoutputformat.compress.type</td> <td>RECORD</td> <td>reducer输出</td> <td>SequenceFile输出使用的压缩类型：NONE和BLOCK</td></tr></tbody></table> <h3 id="开启map输出阶段压缩"><a href="#开启map输出阶段压缩" class="header-anchor">#</a> 开启Map输出阶段压缩</h3> <blockquote><p>开启map输出阶段压缩可以减少job中map和Reduce task间数据传输量。具体配置如下：</p></blockquote> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 1）开启hive中间传输数据压缩功能</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>compress<span class="token punctuation">.</span>intermediate<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token comment">-- 2）开启mapreduce中map输出压缩功能</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>map<span class="token punctuation">.</span>output<span class="token punctuation">.</span>compress<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token comment">-- 3）设置mapreduce中map输出数据的压缩方式</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>map<span class="token punctuation">.</span>output<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>codec<span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>SnappyCodec<span class="token punctuation">;</span>
<span class="token comment">-- 4）执行查询语句</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">from</span> aaaa<span class="token punctuation">;</span>
</code></pre></div><h3 id="开启reduce输出阶段压缩"><a href="#开启reduce输出阶段压缩" class="header-anchor">#</a> 开启Reduce输出阶段压缩</h3> <blockquote><p>当Hive将输出写入到表中时，输出内容同样可以进行压缩。属性hive.exec.compress.output控制着这个功能。用户可能需要保持默认设置文件中的默认值false，这样默认的输出就是非压缩的纯文本文件了。用户可以通过在查询语句或执行脚本中设置这个值为true，来开启输出结果压缩功能。</p></blockquote> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 1）开启hive最终输出数据压缩功能</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>compress<span class="token punctuation">.</span>output<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token comment">-- 2）开启mapreduce最终输出数据压缩</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>output<span class="token punctuation">.</span>fileoutputformat<span class="token punctuation">.</span>compress<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token comment">-- 3）设置mapreduce最终数据输出压缩方式</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>output<span class="token punctuation">.</span>fileoutputformat<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>codec <span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>SnappyCodec<span class="token punctuation">;</span>
<span class="token comment">-- 4）设置mapreduce最终数据输出压缩为块压缩</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>output<span class="token punctuation">.</span>fileoutputformat<span class="token punctuation">.</span>compress<span class="token punctuation">.</span><span class="token keyword">type</span><span class="token operator">=</span>BLOCK<span class="token punctuation">;</span>
<span class="token comment">-- 5）测试一下输出结果是否是压缩文件</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/root/data'</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> aaaa<span class="token punctuation">;</span>
</code></pre></div><h2 id="文件存储格式"><a href="#文件存储格式" class="header-anchor">#</a> 文件存储格式</h2> <blockquote><p>Hive支持的存储数的格式主要有：TEXTFILE 、SEQUENCEFILE、ORC、PARQUET。</p></blockquote> <h3 id="列式存储和行式存储"><a href="#列式存储和行式存储" class="header-anchor">#</a> 列式存储和行式存储</h3> <p><strong>行存储的特点：</strong> 查询满足条件的一整行数据的时候，列存储则需要去每个聚集的字段找到对应的每个列的值，行存储只需要找到其中一个值，其余的值都在相邻地方，所以此时行存储查询的速度更快。</p> <p><strong>列存储的特点：</strong> 因为每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的数据量；每个字段的数据类型一定是相同的，列式存储可以针对性的设计更好的设计压缩算法。</p> <p>TEXTFILE 和 SEQUENCEFILE 的存储格式都是基于行存储的；</p> <p>ORC 和 PARQUET 是基于列式存储的。</p> <h3 id="textfile格式"><a href="#textfile格式" class="header-anchor">#</a> TEXTFILE格式</h3> <blockquote><p>默认格式，数据不做压缩，磁盘开销大，数据解析开销大。可结合Gzip、Bzip2使用(系统自动检查，执行查询时自动解压)，但使用这种方式，hive不会对数据进行切分，从而无法对数据进行并行操作。</p></blockquote> <h3 id="orc格式"><a href="#orc格式" class="header-anchor">#</a> ORC格式</h3> <blockquote><p>Orc (Optimized Row Columnar)是hive 0.11版里引入的新的存储格式。</p></blockquote> <p>​		每个Orc文件由1个或多个stripe组成，每个stripe250MB大小，这个Stripe实际相当于RowGroup概念，不过大小由4MB-&gt;250MB，这样应该能提升顺序读的吞吐率。每个Stripe里有三部分组成，分别是Index Data,Row Data,Stripe Footer：</p> <p><img src="/images/orc%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F.png" alt="orc文件格式"></p> <ol><li>Index Data：一个轻量级的index，默认是每隔1W行做一个索引。这里做的索引应该只是记录某行的各字段在Row Data中的offset。</li> <li>Row Data：存的是具体的数据，先取部分行，然后对这些行按列进行存储。对每个列进行了编码，分成多个Stream来存储。</li> <li>Stripe Footer：存的是各个Stream的类型，长度等信息。</li></ol> <blockquote><p>每个文件有一个File Footer，这里面存的是每个Stripe的行数，每个Column的数据类型信息等；每个文件的尾部是一个PostScript，这里面记录了整个文件的压缩类型以及FileFooter的长度信息等。在读取文件时，会seek到文件尾部读PostScript，从里面解析到File Footer长度，再读FileFooter，从里面解析到各个Stripe信息，再读各个Stripe，即从后往前读。</p></blockquote> <h3 id="parquet格式"><a href="#parquet格式" class="header-anchor">#</a> PARQUET格式</h3> <blockquote><p>Parquet是面向分析型业务的列式存储格式，由Twitter和Cloudera合作开发，2015年5月从Apache的孵化器里毕业成为Apache顶级项目。</p></blockquote> <p>​		Parquet文件是以二进制方式存储的，所以是不可以直接读取的，文件中包括该文件的数据和元数据，因此Parquet格式文件是自解析的。</p> <p>​		通常情况下，在存储Parquet数据的时候会按照Block大小设置行组的大小，由于一般情况下每一个Mapper任务处理数据的最小单位是一个Block，这样可以把每一个行组由一个Mapper任务处理，增大任务执行并行度。Parquet文件的格式如下图所示。</p> <p><img src="/images/parquet%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F.png" alt="parquet文件格式"></p> <p>​		上图展示了一个Parquet文件的内容，一个文件中可以存储多个行组，文件的首位都是该文件的Magic Code，用于校验它是否是一个Parquet文件，Footer length记录了文件元数据的大小，通过该值和文件长度可以计算出元数据的偏移量，文件的元数据中包括每一个行组的元数据信息和该文件存储数据的Schema信息。除了文件中每一个行组的元数据，每一页的开始都会存储该页的元数据，在Parquet中，有三种类型的页：数据页、字典页和索引页。数据页用于存储当前行组中该列的值，字典页存储该列值的编码字典，每一个列块中最多包含一个字典页，索引页用来存储当前行组下该列的索引，目前Parquet中还不支持索引页。</p> <h3 id="主流文件存储格式对比实验"><a href="#主流文件存储格式对比实验" class="header-anchor">#</a> 主流文件存储格式对比实验</h3> <p>从存储文件的压缩比和查询速度两个角度对比。存储文件的压缩比测试：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 1）TextFile</span>
<span class="token comment">--（1）创建表，存储数据格式为TEXTFILE</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> log_text <span class="token punctuation">(</span>track_time string<span class="token punctuation">,</span>url string<span class="token punctuation">,</span>session_id string<span class="token punctuation">,</span>referer string<span class="token punctuation">,</span>ip string<span class="token punctuation">,</span>end_user_id string<span class="token punctuation">,</span>city_id string<span class="token punctuation">)</span><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>stored <span class="token keyword">as</span> textfile <span class="token punctuation">;</span>
<span class="token comment">--（2）向表中加载数据</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/log'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> log_text <span class="token punctuation">;</span>
<span class="token comment">--（3）查看表中数据大小</span>
dfs <span class="token operator">-</span>du <span class="token operator">-</span>h <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_text<span class="token punctuation">;</span>
<span class="token number">18.1</span> M  <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_text<span class="token operator">/</span>log<span class="token punctuation">.</span><span class="token keyword">data</span>
<span class="token comment">-- 2）ORC</span>
<span class="token comment">--（1）创建表，存储数据格式为ORC</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> log_orc<span class="token punctuation">(</span>track_time string<span class="token punctuation">,</span>url string<span class="token punctuation">,</span>session_id string<span class="token punctuation">,</span>referer string<span class="token punctuation">,</span>ip string<span class="token punctuation">,</span>end_user_id string<span class="token punctuation">,</span>city_id string<span class="token punctuation">)</span><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>stored <span class="token keyword">as</span> orc <span class="token punctuation">;</span>
<span class="token comment">--（2）向表中加载数据</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> log_orc <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> log_text <span class="token punctuation">;</span>
<span class="token comment">--（3）查看表中数据大小</span>
dfs <span class="token operator">-</span>du <span class="token operator">-</span>h <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_orc<span class="token operator">/</span> <span class="token punctuation">;</span>
<span class="token number">2.8</span> M  <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_orc<span class="token operator">/</span><span class="token number">000000</span>_0
<span class="token comment">-- 3）Parquet</span>
<span class="token comment">--（1）创建表，存储数据格式为parquet</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> log_parquet<span class="token punctuation">(</span>track_time string<span class="token punctuation">,</span>url string<span class="token punctuation">,</span>session_id string<span class="token punctuation">,</span>referer string<span class="token punctuation">,</span>ip string<span class="token punctuation">,</span>end_user_id string<span class="token punctuation">,</span>city_id string<span class="token punctuation">)</span><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>stored <span class="token keyword">as</span> parquet <span class="token punctuation">;</span>	
<span class="token comment">--（2）向表中加载数据</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> log_parquet <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> log_text <span class="token punctuation">;</span>
<span class="token comment">--（3）查看表中数据大小</span>
dfs <span class="token operator">-</span>du <span class="token operator">-</span>h <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_parquet<span class="token operator">/</span> <span class="token punctuation">;</span>
<span class="token number">13.1</span> M  <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_parquet<span class="token operator">/</span><span class="token number">000000</span>_0
<span class="token comment">-- 存储文件的压缩比总结：</span>
ORC <span class="token operator">&gt;</span>  Parquet <span class="token operator">&gt;</span>  textFile
</code></pre></div><h2 id="存储和压缩结合"><a href="#存储和压缩结合" class="header-anchor">#</a> 存储和压缩结合</h2> <blockquote><p>官网：https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC</p></blockquote> <p>ORC存储方式的压缩：</p> <table><thead><tr><th>Key</th> <th>Default</th> <th>Notes</th></tr></thead> <tbody><tr><td>orc.compress</td> <td>ZLIB</td> <td>high level compression (one of NONE, ZLIB, SNAPPY)</td></tr> <tr><td>orc.compress.size</td> <td>262,144</td> <td>number of bytes in each compression chunk</td></tr> <tr><td>orc.stripe.size</td> <td>67,108,864</td> <td>number of bytes in each stripe</td></tr> <tr><td>orc.row.index.stride</td> <td>10,000</td> <td>number of rows between index entries (must be &gt;= 1000)</td></tr> <tr><td>orc.create.index</td> <td>true</td> <td>whether to create row indexes</td></tr> <tr><td>orc.bloom.filter.columns</td> <td>&quot;&quot;</td> <td>comma separated list of column names for which bloom filter should be created</td></tr> <tr><td>orc.bloom.filter.fpp</td> <td>0.05</td> <td>false positive probability for bloom filter (must &gt;0.0 and &lt;1.0)</td></tr></tbody></table> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 1）创建一个非压缩的的ORC存储方式</span>
<span class="token comment">--（1）建表语句</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> log_orc_none<span class="token punctuation">(</span>track_time string<span class="token punctuation">,</span>url string<span class="token punctuation">,</span>session_id string<span class="token punctuation">,</span>referer string<span class="token punctuation">,</span>ip string<span class="token punctuation">,</span>end_user_id string<span class="token punctuation">,</span>city_id string<span class="token punctuation">)</span><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>stored <span class="token keyword">as</span> orc tblproperties <span class="token punctuation">(</span><span class="token string">&quot;orc.compress&quot;</span><span class="token operator">=</span><span class="token string">&quot;NONE&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">--（2）插入数据</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> log_orc_none <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> log_text <span class="token punctuation">;</span>
<span class="token comment">--（3）查看插入后数据</span>
dfs <span class="token operator">-</span>du <span class="token operator">-</span>h <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_orc_none<span class="token operator">/</span> <span class="token punctuation">;</span>
<span class="token number">7.7</span> M  <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_orc_none<span class="token operator">/</span><span class="token number">000000</span>_0
<span class="token comment">-- 2）创建一个SNAPPY压缩的ORC存储方式</span>
<span class="token comment">--（1）建表语句</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> log_orc_snappy<span class="token punctuation">(</span>track_time string<span class="token punctuation">,</span>url string<span class="token punctuation">,</span>session_id string<span class="token punctuation">,</span>referer string<span class="token punctuation">,</span>ip string<span class="token punctuation">,</span>end_user_id string<span class="token punctuation">,</span>city_id string<span class="token punctuation">)</span><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>stored <span class="token keyword">as</span> orc tblproperties <span class="token punctuation">(</span><span class="token string">&quot;orc.compress&quot;</span><span class="token operator">=</span><span class="token string">&quot;SNAPPY&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">--（2）插入数据</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> log_orc_snappy <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> log_text <span class="token punctuation">;</span>
<span class="token comment">--（3）查看插入后数据</span>
dfs <span class="token operator">-</span>du <span class="token operator">-</span>h <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_orc_snappy<span class="token operator">/</span> <span class="token punctuation">;</span>
<span class="token number">3.8</span> M  <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_orc_snappy<span class="token operator">/</span><span class="token number">000000</span>_0
<span class="token comment">-- 3）上一节中默认创建的ORC存储方式，导入数据后的大小为</span>
<span class="token number">2.8</span> M  <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_orc<span class="token operator">/</span><span class="token number">000000</span>_0
<span class="token comment">--总结</span>
比Snappy压缩的还小。原因是orc存储文件默认采用ZLIB压缩。比snappy压缩的小。
</code></pre></div><h2 id="hive-high-avaliable"><a href="#hive-high-avaliable" class="header-anchor">#</a> hive—high Avaliable</h2> <blockquote><p>使用hiveserver2的优点如下</p> <ol><li>在应用端不需要部署hadoop和hive的客户端</li> <li>hiveserver2不用直接将hdfs和metastore暴露给用户</li> <li>有HA机制，解决应用端的并发和负载问题</li> <li>jdbc的连接方式，可以使用任何语言，方便与应用进行数据交互</li></ol></blockquote> <p><strong>本文主要介绍如何进行hive的HA的搭建：</strong></p> <p>如何进行搭建，参照之前hadoop的HA，使用zookeeper完成HA</p> <h3 id="执行配置"><a href="#执行配置" class="header-anchor">#</a> 执行配置</h3> <p>需要做HA的机器做如下配置</p> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>  
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.metastore.warehouse.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>  
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>/var/bigdata/hive-ha/warehouse<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>  
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>  
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>  
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>javax.jdo.option.ConnectionURL<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>  
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>jdbc:mysql://software:3306/hive-ha?createDatabaseIfNotExist=true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>  
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>  
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>  
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>javax.jdo.option.ConnectionDriverName<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>  
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>com.mysql.cj.jdbc.Driver<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>  
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>     
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>  
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>javax.jdo.option.ConnectionUserName<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>  
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>root<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>  
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>  
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>  
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>javax.jdo.option.ConnectionPassword<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>  
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>tiankafei<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>  
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.server2.support.dynamic.service.discovery<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.server2.zookeeper.namespace<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hiveserver2_ha<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.zookeeper.quorum<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>bigdata01:2181,bigdata02:2181,bigdata03:2181,bigdata04:2181<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.zookeeper.client.port<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>2181<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.server2.thrift.bind.host<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>当前主机名<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.server2.thrift.port<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>10001<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span> 
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><h3 id="使用jdbc或者beeline两种方式进行访问"><a href="#使用jdbc或者beeline两种方式进行访问" class="header-anchor">#</a> 使用jdbc或者beeline两种方式进行访问</h3> <ol><li><p>beeline</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token operator">!</span>connect jdbc:hive2://bigdata01,bigdata02,bigdata03,bigdata04/<span class="token punctuation">;</span><span class="token assign-left variable">serviceDiscoveryMode</span><span class="token operator">=</span>zooKeeper<span class="token punctuation">;</span><span class="token assign-left variable">zooKeeperNamespace</span><span class="token operator">=</span>hiveserver2_ha root tiankafei
</code></pre></div></li> <li><p>jdbc</p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">try</span> <span class="token punctuation">{</span>
    <span class="token class-name">Class</span><span class="token punctuation">.</span><span class="token function">forName</span><span class="token punctuation">(</span><span class="token string">&quot;org.apache.hive.jdbc.HiveDriver&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ClassNotFoundException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token class-name">Connection</span> conn <span class="token operator">=</span> <span class="token class-name">DriverManager</span><span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span><span class="token string">&quot;jdbc:hive2://bigdata01,bigdata02,bigdata03,bigdata04/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2_ha&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;tiankafei&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Statement</span> stmt <span class="token operator">=</span> conn<span class="token punctuation">.</span><span class="token function">createStatement</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">String</span> sql <span class="token operator">=</span> <span class="token string">&quot;select * from psn limit 5&quot;</span><span class="token punctuation">;</span>
<span class="token class-name">ResultSet</span> res <span class="token operator">=</span> stmt<span class="token punctuation">.</span><span class="token function">executeQuery</span><span class="token punctuation">(</span>sql<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">while</span> <span class="token punctuation">(</span>res<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>res<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre></div></li></ol></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">6/15/2020, 1:01:06 AM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/tiankafei-docs-大数据/Hadoop程序运行的三种方式.html" class="prev">
        Hadoop程序运行的三种方式
      </a></span> <span class="next"><a href="/tiankafei-docs-大数据/centos7安装配置HBase.html">
        centos7安装配置HBase
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.a9dae821.js" defer></script><script src="/assets/js/2.63c13255.js" defer></script><script src="/assets/js/100.ffa5fdd6.js" defer></script>
  </body>
</html>
